{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c058b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_video_path=f'/Users/jiyeong/Desktop/컴공 캡스톤/Dataset/ff++/val/*'\n",
    "input_video_path=f'/Users/jiyeong/Desktop/컴공 캡스톤/Dataset/ff++/train/fake'    # input\n",
    "output_video_path=f'/Users/jiyeong/Desktop/컴공 캡스톤/output/fake_ff'   # 영상 output 저장하는 경로\n",
    "frame_path=f'/Users/jiyeong/Desktop/컴공 캡스톤/output/fake_ff/jpg'      # jpg output 저장하는 경로\n",
    "checkpoint_path=f'/Users/jiyeong/HUFS.CSE.DE-fake-it/model/checkpoints'\n",
    "predictions_file_path = '/Users/jiyeong/Desktop/컴공 캡스톤/Dataset/ff+(train)_video_predictions.xlsx' # 예측 후 메타 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2acfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efded1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ MPS 디바이스 설정\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea7f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 모델 정의\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size, seq_length, 2048)\n",
    "        x_lstm, _ = self.lstm(x, None)\n",
    "        return fmap, self.dp(self.linear1(x_lstm[:, -1, :]))\n",
    "\n",
    "# ✅ Grad-CAM 계산 함수\n",
    "def compute_gradcam(model, input_tensor, target_class=None):\n",
    "    model.eval()\n",
    "    fmap = None\n",
    "    grad = None\n",
    "\n",
    "    def fw_hook(module, inp, out):\n",
    "        nonlocal fmap\n",
    "        fmap = out.detach()\n",
    "\n",
    "    def bw_hook(module, grad_in, grad_out):\n",
    "        nonlocal grad\n",
    "        grad = grad_out[0].detach()\n",
    "\n",
    "    last_layer = model.model[-1]\n",
    "    f = last_layer.register_forward_hook(fw_hook)\n",
    "    b = last_layer.register_backward_hook(bw_hook)\n",
    "\n",
    "    input_tensor = input_tensor.to(device).unsqueeze(0).unsqueeze(0).requires_grad_(True)\n",
    "    _, output = model(input_tensor)\n",
    "\n",
    "    if target_class is None:\n",
    "        target_class = output.argmax(dim=1).item()\n",
    "\n",
    "    model.zero_grad()\n",
    "    output[0, target_class].backward()\n",
    "\n",
    "    weights = grad.mean(dim=[2, 3], keepdim=True)\n",
    "    cam = (weights * fmap).sum(dim=1, keepdim=True)\n",
    "    cam = F.relu(cam)\n",
    "    cam = cam.squeeze().cpu().numpy()\n",
    "    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "    cam = cv2.resize(cam, (input_tensor.shape[-1], input_tensor.shape[-2]))\n",
    "\n",
    "    f.remove()\n",
    "    b.remove()\n",
    "    return cam\n",
    "\n",
    "# ✅ MJPEG 처리 및 저장 함수\n",
    "def process_video_and_save_frames(input_video_path, output_video_path, model, frame_dir=f'{frame_path}'):\n",
    "    os.makedirs(frame_dir, exist_ok=True)\n",
    "    input_path = f'{input_video_path}/*.mp4'  #Input file path, 입력 파일 경로 - 파일 경로 수정!!\n",
    "    video_files = glob.glob(input_path)\n",
    "\n",
    "    # Ensure to use MPS for MacBook -MPS GPu 사용하기\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    # 이미 처리되어 저장된 영상 개수 확인\n",
    "    already_present_count = glob.glob(output_video_path+ '/*.mp4')\n",
    "    print(\"No of videos already present \", len(already_present_count))\n",
    "\n",
    "    # Excel 파일 로드\n",
    "    df = pd.read_excel(predictions_file_path)\n",
    "\n",
    "\n",
    "    for video_file in video_files:\n",
    "        out_path = os.path.join(output_video_path,video_file.split('/')[-1]) # 영상 파일 이름 추출\n",
    "        print(out_path)\n",
    "\n",
    "        file_exists = glob.glob(out_path)\n",
    "        print(file_exists)\n",
    "        if(len(file_exists) != 0): # 이미 존재하면 pass\n",
    "            print(\"File Already exists: \" , out_path)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        result = str(df[df['Filepath'] == video_file]['label'].iloc[0])[0] + str(df[df['Filepath'] == video_file]['Prediction'].iloc[0])[0]\n",
    "\n",
    "\n",
    "        # 고유한 파일 이름으로 저장\n",
    "        filename = os.path.basename(video_file)\n",
    "        name, _ = os.path.splitext(filename)\n",
    "        output_path = os.path.join(output_video_path, f\"({result})_{name}.mp4\")\n",
    "\n",
    "        # MP4로 저장\n",
    "        out = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc('M','J','P','G'), fps, (w, h))\n",
    "\n",
    "        transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Resize((224, 224)),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        frame_count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            original = frame.copy()\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = transform(img).to(device)\n",
    "\n",
    "            cam = compute_gradcam(model, img)\n",
    "            heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "            heatmap = cv2.resize(heatmap, (original.shape[1], original.shape[0]))\n",
    "            overlay = 0.4 * heatmap + 0.6 * original\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "\n",
    "            out.write(overlay)\n",
    "\n",
    "            # 프레임 저장\n",
    "            frame_path = os.path.join(frame_dir, f\"({result})_{name}_{frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_path, overlay)\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"✅ Grad-CAM 영상 저장 완료: {output_video_path}\")\n",
    "        print(f\"✅ 프레임 이미지 {frame_count}개 저장됨: {frame_dir}/frame_XXXX.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes=2)\n",
    "model.load_state_dict(torch.load(f\"{checkpoint_path}/checkpoint.pt\", map_location=device))\n",
    "\n",
    "process_video_and_save_frames(\n",
    "    input_video_path,\n",
    "    output_video_path,\n",
    "    model=model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c78bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
