{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDvwC4EREIbq"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds21w9F6PkHc"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBUsl72t-dMd"
   },
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAgV--qT0bis"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "input_file_path='/content/drive/MyDrive/Capstone/Dataset/ff++/train/*/*'\n",
    "base_path='/content/drive/MyDrive/Capstone/Dataset/'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/ff++'\n",
    "\n",
    "num_epochs=30 # 에폭 횟수\n",
    "checkpoint_name=\"checkpoint_v33\" # 체크포인트 이름\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "frames=150\n",
    "\n",
    "\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"model_name : {selected_model}\")\n",
    "print(f\"Dataset : FaceForencis++\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print(f\"Training for {num_epochs} epochs\")\n",
    "print()\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import face_recognition\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import seaborn as sn\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import timm\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from sklearn.metrics import confusion_matrix  #내가 추가함\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# device / 디바이스 설정\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. load the video name and labels from csv / metadata에서 real/fake 여부 가져오기\n",
    "class video_dataset(Dataset):\n",
    "    def __init__(self,video_names,labels,sequence_length = 60,transform = None):\n",
    "        self.video_names = video_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "    def __getitem__(self,idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        # a = int(100/self.count)\n",
    "        # first_frame = np.random.randint(0,a)\n",
    "        temp_video = video_path.split('/')[-1]\n",
    "        label = self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
    "        if(label == 'FAKE'):\n",
    "          label = 0\n",
    "        if(label == 'REAL'):\n",
    "          label = 1\n",
    "\n",
    "        method_str= self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),2]\n",
    "\n",
    "        # method를 숫자 라벨로 매핑\n",
    "        method_dict = {'original': 0, 'Deepfakes': 1, 'FaceShifter': 2, 'FaceSwap': 3, 'NeuralTextures': 4, 'Face2Face':5, 'others': 6 }\n",
    "        method = method_dict[method_str]\n",
    "\n",
    "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
    "          frames.append(self.transform(frame))\n",
    "          if(len(frames) == self.count):\n",
    "            break\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]\n",
    "        return frames,label,method\n",
    "\n",
    "    def frame_extract(self,path):\n",
    "      vidObj = cv2.VideoCapture(path)\n",
    "      success = 1\n",
    "      while success:\n",
    "          success, image = vidObj.read()\n",
    "          if success:\n",
    "              yield image\n",
    "\n",
    "# count the number of fake and real videos / real fake 영상 개수 세기\n",
    "def number_of_real_and_fake_videos(data_list):\n",
    "  header_list = [\"file\",\"label\",\"method\"]\n",
    "  lab = pd.read_csv(f'{meta_data_path}/Global_metadata.csv',names=header_list)\n",
    "  fake = 0\n",
    "  real = 0\n",
    "  original=0\n",
    "  deepfakes=0\n",
    "  faceshifter=0\n",
    "  faceswap=0\n",
    "  neuraltextures=0\n",
    "  face2face=0\n",
    "  others=0\n",
    "  for i in data_list:\n",
    "    temp_video = i.split('/')[-1]\n",
    "    label = lab.iloc[(lab.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
    "    if(label == 'FAKE'):\n",
    "      fake+=1\n",
    "    if(label == 'REAL'):\n",
    "      real+=1\n",
    "    method = lab.iloc[(lab.loc[labels[\"file\"] == temp_video].index.values[0]),2]\n",
    "    method = method.lower()\n",
    "    if(method == 'original'):\n",
    "      original+=1\n",
    "    elif(method == 'deepfakes'):\n",
    "      deepfakes+=1\n",
    "    elif(method == 'faceshifter'):\n",
    "      faceshifter+=1\n",
    "    elif(method == 'faceswap'):\n",
    "      faceswap+=1\n",
    "    elif(method == 'neuraltextures'):\n",
    "      neuraltextures+=1\n",
    "    elif(method == 'face2face'):\n",
    "      face2face+=1\n",
    "    else:\n",
    "       others+=1\n",
    "\n",
    "\n",
    "  return real,fake,original, deepfakes,faceshifter, faceswap, neuraltextures,face2face, others\n",
    "\n",
    "\n",
    "# load the labels and video in data loader\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#2. to load preprocessod video to memory / 전처리된 영상 가져오기\n",
    "video_files = sorted(glob.glob(f'{input_file_path}/*.mp4'))\n",
    "# random.shuffle(video_files)\n",
    "\n",
    "header_list = [\"file\",\"label\",\"method\"]\n",
    "labels = pd.read_csv(f'{meta_data_path}/Global_metadata.csv',names=header_list)\n",
    "\n",
    "# train_videos = video_files[:int(0.9*len(video_files))]  # 8:2으로 train:test\n",
    "# valid_videos = video_files[int(0.9*len(video_files)):]\n",
    "train_videos, valid_videos = train_test_split(video_files, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"train : \" , len(train_videos))\n",
    "print(\"Validation : \" , len(valid_videos))\n",
    "\n",
    "train_count=number_of_real_and_fake_videos(train_videos)\n",
    "test_count=number_of_real_and_fake_videos(valid_videos)\n",
    "print(f\"TRAIN:  Real: {train_count[0]} Fake: {train_count[1]} original : {train_count[2]} Deepfakes : {train_count[3]}\",\n",
    "      f\"FaceShifter : {train_count[4]}  FaceSwap : {train_count[5]} NeuralTextures : {train_count[6]} Face2Face {train_count[7]} others : {train_count[8]}\")\n",
    "print(f\"VALIDATION:  Real: {test_count[0]} Fake: {test_count[1]} original : {test_count[2]} Deepfakes : {test_count[3]}\",\n",
    "      f\"FaceShifter : {test_count[4]}  FaceSwap : {test_count[5]} NeuralTextures : {test_count[6]} Face2Face {test_count[7]} others : {test_count[8]}\")\n",
    "im_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "train_data = video_dataset(train_videos,labels,sequence_length = 10,transform = train_transforms)\n",
    "#print(train_data)\n",
    "val_data = video_dataset(valid_videos,labels,sequence_length = 10,transform = test_transforms)\n",
    "\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "  train_loader = DataLoader(train_data,batch_size = 8,shuffle = True,num_workers = 2,pin_memory=True)\n",
    "  valid_loader = DataLoader(val_data,batch_size = 8,shuffle = True,num_workers = 2,pin_memory=True)\n",
    "else:\n",
    "# cpu사용하기 때문에 병렬처리 뻄\n",
    "  train_loader = DataLoader(train_data,batch_size = 16,shuffle = True,num_workers = 0)  # 여기서 batch size 조정 (한번에 몇개의 데이터를 묶어서 학습할지, batch개수=데이터 수/batch size)\n",
    "  valid_loader = DataLoader(val_data,batch_size = 16,shuffle = True,num_workers = 0)\n",
    "\n",
    "#Model with feature visualization\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()   \n",
    "        self.dp = nn.Dropout(0.5)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # 두 개의 출력: 이진 분류와 method 분류\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "\n",
    "# 모델을 device로 보내기\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "input_tensor = torch.from_numpy(np.empty((1, 20, 3, 224,224))).type(torch.FloatTensor).to(device)\n",
    "\n",
    "# 모델 실행\n",
    "fmap, output_bin, output_method = model(input_tensor)\n",
    "\n",
    "\n",
    "def train_epoch(epoch, num_epochs, data_loader, model, criterion_bin, criterion_method, optimizer):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    t = []\n",
    "\n",
    "    for i, (inputs,targets_bin, targets_method) in enumerate(data_loader):\n",
    "        # GPU에서 실행\n",
    "        # inputs, targets device로 올리기\n",
    "        inputs = inputs.to(device)\n",
    "        targets_bin = targets_bin.to(device)\n",
    "        targets_method = targets_method.to(device)\n",
    "\n",
    "        _, output_bin, output_method = model(inputs)\n",
    "        # gpu에서 실행\n",
    "        loss_bin = criterion_bin(output_bin, targets_bin)\n",
    "        loss_method = criterion_method(output_method, targets_method)\n",
    "        loss = loss_bin + loss_method\n",
    "\n",
    "        acc = calculate_accuracy(output_bin, targets_bin)\n",
    "        acc_method = calculate_accuracy(output_method, targets_method)\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        accuracies.update(acc, inputs.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%, Acc(method): %.2f%%]\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    num_epochs,\n",
    "                    i,\n",
    "                    len(data_loader),\n",
    "                    losses.avg,\n",
    "                    accuracies.avg,\n",
    "                    acc_method,\n",
    "                    ))\n",
    "\n",
    "    # save the model / 모델 저장\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), f'{checkpoint_path}/{checkpoint_name}.pt')\n",
    "\n",
    "    return losses.avg,accuracies.avg,acc_method\n",
    "\n",
    "def test(epoch,model, data_loader ,criterion_bin, criterion_method):\n",
    "    print('Testing')\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    pred_bin= []\n",
    "    true_bin= []\n",
    "    pred_method = []\n",
    "    true_method = []\n",
    "    output_bin_all = [] # for ROC\n",
    "    feature_list = [] # for t-SNE\n",
    "\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets_bin, targets_method) in enumerate(data_loader):\n",
    "            model = model.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            targets_bin = targets_bin.to(device)\n",
    "            targets_method = targets_method.to(device)\n",
    "\n",
    "\n",
    "            fmap, output_bin, output_method = model(inputs)\n",
    "            batch_size, seq_length = inputs.shape[0], inputs.shape[1]\n",
    "            features = fmap.view(batch_size, seq_length, -1).mean(dim=1)# 평균 pooling\n",
    "            feature_list.append(features.cpu().numpy())\n",
    "            output_bin_all.append(output_bin.detach().cpu())\n",
    "            # GPu cuda 사용\n",
    "            loss_bin = criterion_bin(output_bin, targets_bin)\n",
    "            loss_method = criterion_method(output_method, targets_method)\n",
    "            loss = loss_bin + loss_method\n",
    "\n",
    "            acc = calculate_accuracy(output_bin, targets_bin)\n",
    "            acc_method = calculate_accuracy(output_method, targets_method)\n",
    "            #\n",
    "            _, p_bin = torch.max(output_bin, 1)\n",
    "            _, p_method = torch.max(output_method, 1)\n",
    "            true_bin += targets_bin.cpu().numpy().tolist()\n",
    "            pred_bin += p_bin.cpu().numpy().tolist()\n",
    "            true_method += targets_method.cpu().numpy().tolist()\n",
    "            pred_method += p_method.cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            accuracies.update(acc, inputs.size(0))\n",
    "            sys.stdout.write(\n",
    "                    \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%, Acc(method): %.2f%%]\"\n",
    "                    % (\n",
    "                        i,\n",
    "                        len(data_loader),\n",
    "                        losses.avg,\n",
    "                        accuracies.avg,\n",
    "                        acc_method,\n",
    "                        )\n",
    "                    )\n",
    "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
    "\n",
    "    output_bin_all = torch.cat(output_bin_all, dim=0)  # [N, 2] 형태로 만듦\n",
    "    feature_array = np.concatenate(feature_list, axis=0)  # [N, D] 형태\n",
    "    return true_bin, pred_bin, true_method, pred_method,losses.avg,accuracies.avg,acc_method,output_bin_all,feature_array\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def calculate_accuracy(outputs, targets): # top-1 accuracy\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "    return 100* n_correct_elems / batch_size\n",
    "\n",
    "#Output confusion matrix / 모델 성능 평가\n",
    "\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'로 정수 표현\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    # plt.show()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot.png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # 성능 출력\n",
    "    print(\"📊 Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\n📈 Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "def print_confusion_matrix_method(y_true_method, y_pred_method):\n",
    "\n",
    "    labels = ['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face','others']\n",
    "    label_indices = list(range(len(labels))) # [0, 1, 2, ..., 6]\n",
    "    cm = confusion_matrix(y_true_method, y_pred_method, labels=label_indices)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Blues')\n",
    "    plt.ylabel('Actual label', size=16)\n",
    "    plt.xlabel('Predicted label', size=16)\n",
    "    plt.xticks(np.arange(len(labels)) + 0.5, labels, rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(np.arange(len(labels)) + 0.5, labels, rotation=0, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(method).png')\n",
    "\n",
    "    # 정확도 계산: 모든 정답 예측 수 / 전체 샘플 수\n",
    "    correct_preds = np.trace(cm)\n",
    "    total_preds = np.sum(cm)\n",
    "    calculated_acc = correct_preds / total_preds\n",
    "    print(f\"\\n✅ Calculated Accuracy: {calculated_acc * 100:.2f}%\")\n",
    "\n",
    "    # 성능 출력\n",
    "    print(\"📊 Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\n📈 Classification Report:\")\n",
    "    print(classification_report(y_true_method, y_pred_method, target_names=labels, labels=label_indices))\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    \"\"\"\n",
    "    ROC Curve를 그리고 저장합니다.\n",
    "\n",
    "    Parameters:\n",
    "        - true_bin: List[int], 실제 레이블 (0=Fake, 1=Real)\n",
    "        - output_bin: Tensor[N, 2], 모델의 softmax 전 이진 분류 출력\n",
    "    \"\"\"\n",
    "    pred_score = torch.softmax(output_bin, dim=1)[:, 1].cpu().numpy()  # Real 확률\n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'✅ ROC curve (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve.png\")\n",
    "    print(f\"✅ ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve.png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(features, labels, checkpoint_path, checkpoint_name, method_labels=None):\n",
    "    \"\"\"\n",
    "    t-SNE를 이용한 다중 클래스 시각화를 수행하고 저장합니다.\n",
    "\n",
    "    Parameters:\n",
    "        - features: List or np.ndarray, (N, D) CNN or LSTM feature vectors\n",
    "        - labels: List[int], (N,) 클래스 인덱스 (ex. 0~5)\n",
    "        - checkpoint_path: 저장 디렉토리\n",
    "        - checkpoint_name: 저장 파일 이름 접두사\n",
    "        - method_labels: List[str], 각 클래스에 대응되는 문자열 레이블(optional)\n",
    "    \"\"\"\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, max(5, n_samples // 3))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_classes = np.unique(labels)\n",
    "    for cls in unique_classes:\n",
    "        idx = labels == cls\n",
    "        label_name = method_labels[cls] if method_labels and cls < len(method_labels) else str(cls)\n",
    "        plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=label_name, alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Method Class Features')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_tsne.png\")\n",
    "    print(f\"✅ t-SNE plot saved to {checkpoint_path}/{checkpoint_name}_tsne.png\")\n",
    "\n",
    "\n",
    "# loss 그래프\n",
    "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
    "  loss_train = train_loss_avg\n",
    "  loss_val = test_loss_avg\n",
    "  print(num_epochs)\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.clf()  # Clear the previous figure\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "  plt.title('Training and Validation loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  # plt.show()\n",
    "  plt.savefig(f'{checkpoint_path}/{checkpoint_name}_loss_plot.png')\n",
    "\n",
    "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
    "  loss_train = train_accuracy\n",
    "  loss_val = test_accuracy\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.clf()  # Clear the previous figure\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "  plt.title('Training and Validation accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  # plt.show()\n",
    "  plt.savefig(f'{checkpoint_path}/{checkpoint_name}_accuracy_plot.png')\n",
    "\n",
    "\n",
    "\n",
    "#learning rate\n",
    "lr = 1e-4             #시작 1e-5#0.001\n",
    "#number of epochs (맨 위에서 설정)\n",
    "#num_epochs = 2\n",
    "\n",
    "# criterion_bin = nn.CrossEntropyLoss().to(device)\n",
    "weights = torch.tensor([0.7,1.75]).to(device)  # [fake, real]의 순서라고 가정\n",
    "criterion_bin = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "criterion_method = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= lr,weight_decay = 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "# 🔧 ReduceLROnPlateau 스케줄러 추가\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# 체크포인트가 존재하면 불러오기\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "checkpoint_file = f'{checkpoint_path}/{checkpoint_name}.pt'\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])  # 추가\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"📦 체크포인트에서 학습 재개: Epoch {start_epoch}부터\")\n",
    "    train_loss_avg = checkpoint['train_loss']\n",
    "    train_accuracy = checkpoint['train_acc']\n",
    "    test_loss_avg = checkpoint['val_loss']\n",
    "    test_accuracy = checkpoint['val_acc']\n",
    "    best_auc = checkpoint['best_auc']\n",
    "\n",
    "else:\n",
    "    print(\"🚨 체크포인트가 없어 처음부터 시작합니다.\")\n",
    "    start_epoch = 1\n",
    "    train_loss_avg, train_accuracy = [], []\n",
    "    test_loss_avg, test_accuracy = [], []\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "    print(f\"💾 체크포인트 저장 완료: {filename}\")\n",
    "\n",
    "best_auc = 0.0\n",
    "best_epoch=0\n",
    "best_model_path = f\"{checkpoint_path}/{checkpoint_name}_best.pt\"\n",
    "\n",
    "# 시간 측정 시작\n",
    "start_time = time.time()\n",
    "for epoch in range(start_epoch, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    l, acc ,m_acc= train_epoch(epoch,num_epochs,train_loader,model,criterion_bin, criterion_method,optimizer)\n",
    "    train_loss_avg.append(l)\n",
    "    train_accuracy.append(acc)\n",
    "    true_bin, pred_bin, true_method, pred_method, tl, t_acc, m_acc,output_bin_all,feature_array= test(epoch,model,valid_loader,criterion_bin, criterion_method)\n",
    "    test_loss_avg.append(tl)\n",
    "    test_accuracy.append(t_acc)\n",
    "\n",
    "    # 🔧 ReduceLROnPlateau 스케줄러 실행\n",
    "    scheduler.step(tl)\n",
    "\n",
    "    # 현재 learning rate 확인\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"📉 현재 Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_elapsed = epoch_end_time - epoch_start_time\n",
    "    print(f\"✅ Epoch {epoch} 소요 시간: {epoch_elapsed:.2f}초\")\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),  # 추가\n",
    "        'train_loss': train_loss_avg,\n",
    "        'train_acc': train_accuracy,\n",
    "        'val_loss': test_loss_avg,\n",
    "        'val_acc': test_accuracy,\n",
    "        'best_auc':best_auc\n",
    "    }, checkpoint_file)\n",
    "\n",
    "    # AUC 계산\n",
    "    pred_score = torch.softmax(output_bin_all, dim=1)[:, 1].cpu().numpy()\n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"🎯 AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # 성능이 가장 좋으면 따로 저장\n",
    "    if roc_auc > best_auc:\n",
    "      best_auc = roc_auc\n",
    "      best_epoch=epoch\n",
    "      torch.save(model.state_dict(), best_model_path)\n",
    "      print(f\"🌟 Best 모델 저장됨 ({epoch} epoch에서 AUC={roc_auc:.4f}): {best_model_path}\")\n",
    "\n",
    "      print(confusion_matrix(true_bin,pred_bin)) #confusion_matrix(이진 분류)\n",
    "      print(confusion_matrix(true_method, pred_method))  #confusion_matrix(다중 분류)\n",
    "      plot_roc_curve(true_bin, output_bin_all, checkpoint_path, f\"{checkpoint_name}_best_point\") # ROC Curve (이진 분류)\n",
    "      plot_tsne(feature_array, true_method, checkpoint_path, f\"{checkpoint_name}_best_point\",    # t-SNE (다중 분류)\n",
    "                method_labels=['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face', 'others'])\n",
    "\n",
    "    if epoch%5==0:\n",
    "      plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
    "      plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 시간 측정 끝\n",
    "end_time = time.time()\n",
    "\n",
    "plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
    "plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
    "print(confusion_matrix(true_bin,pred_bin))\n",
    "elapsed_time = end_time - start_time\n",
    "# auc값\n",
    "pred_score = torch.softmax(output_bin_all, dim=1)[:, 1].cpu().numpy()  # Real 확률\n",
    "fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'✅ ROC curve (AUC = {roc_auc:.4f})')\n",
    "print(f\"✅ 전체 학습 소요 시간: {elapsed_time:.2f}초\")\n",
    "\n",
    "print(\"--------------------------------------------------------Report---------------------------------------------\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "print(f\"✅ 전체 학습 소요 시간: {elapsed_time:.2f}초\")\n",
    "print(f'lr = {lr}, epoch = {num_epochs}')\n",
    "print(f'🌟 Best 모델 저장됨 ({best_epoch} epoch에서 AUC={best_auc:.4f}): {best_model_path}로 저장됨')\n",
    "\n",
    "print_confusion_matrix(true_bin,pred_bin)     #confusion_matrix(이진 분류)\n",
    "print_confusion_matrix_method(true_method, pred_method)  #confusion_matrix(다중 분류)\n",
    "plot_roc_curve(true_bin, output_bin_all, checkpoint_path, checkpoint_name) # ROC Curve (이진 분류)\n",
    "plot_tsne(feature_array, true_method, checkpoint_path, checkpoint_name,    # t-SNE (다중 분류)\n",
    "          method_labels=['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face', 'others'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxgBUK9Mx0Gl"
   },
   "source": [
    "# FaceForencis++ test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzGGHmGuezSE"
   },
   "outputs": [],
   "source": [
    "# # 코랩 서버\n",
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "checkpoint_name=\"checkpoint_v33\"\n",
    "\n",
    "test_input_file_path='/content/drive/MyDrive/Capstone/Dataset/ff++/test/*/*'\n",
    "# test_input_file_path2='/content/drive/MyDrive/Capstone/Dataset/DFDC/test/*/*'\n",
    "# test_input_file_path3='/content/drive/MyDrive/Capstone/Dataset/celeb-df/test/*/*'\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/ff++'\n",
    "base_path = '/content/drive/MyDrive/Capstone/Dataset'  # 상대 주소 찾기 위해 base_path 제거\n",
    "frames=150\n",
    "\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"Dataset: FaceForencis++\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print()\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "#Model with feature visualization\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           #  model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "           #  self.model = model.extract_features\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()    # 이거는 넣고 빼고 실험해보래\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        # self.linear1 = nn.Linear(hidden_dim,num_classes) # hidden_dim 변수로 넣어줌\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # 두 개의 출력: 이진 분류와 method 분류\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        # return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "# 디바이스 설정\n",
    "device = get_device()\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "\n",
    "# 모델 구조를 다시 정의\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "model.load_state_dict(torch.load(f'{checkpoint_path}/{checkpoint_name}.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Output confusion matrix   성능 평가\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix  #내가 추가함\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Output confusion matrix / 모델 성능 평가\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'로 정수 표현\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(test).png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # 성능 출력\n",
    "    print(\"📊 Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\n📈 Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "def print_confusion_matrix_method(y_true_method, y_pred_method):\n",
    "\n",
    "    labels = ['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face','others']\n",
    "    label_indices = list(range(len(labels))) # [0, 1, 2, ..., 6]\n",
    "    cm = confusion_matrix(y_true_method, y_pred_method, labels=label_indices)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Blues')\n",
    "    plt.ylabel('Actual label', size=16)\n",
    "    plt.xlabel('Predicted label', size=16)\n",
    "    plt.xticks(np.arange(len(labels)) + 0.5, labels, rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(np.arange(len(labels)) + 0.5, labels, rotation=0, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(method)(test).png')\n",
    "\n",
    "    # 정확도 계산: 모든 정답 예측 수 / 전체 샘플 수\n",
    "    correct_preds = np.trace(cm)\n",
    "    total_preds = np.sum(cm)\n",
    "    calculated_acc = correct_preds / total_preds\n",
    "    print(f\"\\n✅ Calculated Accuracy: {calculated_acc * 100:.2f}%\")\n",
    "\n",
    "    # 성능 출력\n",
    "    print(\"📊 Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\n📈 Classification Report:\")\n",
    "    print(classification_report(y_true_method, y_pred_method, target_names=labels, labels=label_indices))\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    pred_score = output_bin.cpu().numpy()  # Real 확률\n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve(test).png\")\n",
    "    print(f\"✅ ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve(test).png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(features, labels, checkpoint_path, checkpoint_name, method_labels=None):\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, max(5, n_samples // 3))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_classes = np.unique(labels)\n",
    "    for cls in unique_classes:\n",
    "        idx = labels == cls\n",
    "        label_name = method_labels[cls] if method_labels and cls < len(method_labels) else str(cls)\n",
    "        plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=label_name, alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Method Class Features')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_tsne(test).png\")\n",
    "    print(f\"✅ t-SNE plot saved to {checkpoint_path}/{checkpoint_name}_tsne(test).png\")\n",
    "\n",
    "def plot_tsne_binary(features, labels, checkpoint_path, checkpoint_name):\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, max(5, n_samples // 3))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cls in np.unique(labels):\n",
    "        idx = labels == cls\n",
    "        label_name = 'REAL' if cls == 1 else 'FAKE'\n",
    "        plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=label_name, alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Binary Classification Features')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_tsne_binary(test).png\")\n",
    "    print(f\"✅ t-SNE (Binary) plot saved to {checkpoint_path}/{checkpoint_name}_tsne_binary(test).png\")\n",
    "\n",
    "#2. to load preprocessod video to memory / 전처리된 영상 가져오기\n",
    "new_video_files =  glob.glob(f'{test_input_file_path}/*.mp4')\n",
    "\n",
    "random.shuffle(new_video_files)\n",
    "\n",
    "# ✅ 결과 저장 리스트 초기화\n",
    "method_pred_list = []  # ROC Curve 용\n",
    "video_bin_scores = []   # t-SNE 시각화용\n",
    "\n",
    "# ✅ 결과 저장 리스트 초기화\n",
    "results = []\n",
    "label_list = []\n",
    "folder_path_list = []\n",
    "method_list = []\n",
    "\n",
    "\n",
    "video_feature_array = []\n",
    "with torch.no_grad():\n",
    "    for video_path in tqdm(new_video_files):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_preds = []\n",
    "        method_preds=[]\n",
    "        pooled_features_per_video = []\n",
    "        frame_scores = []\n",
    "\n",
    "        frame_idx = 0\n",
    "\n",
    "        relative_path = os.path.relpath(video_path,base_path).replace(\"\\\\\", \"/\")\n",
    "        folder_path_list.append(relative_path)\n",
    "\n",
    "        # label (real/fake)\n",
    "        if 'real' in relative_path.lower():\n",
    "            label = 'REAL'\n",
    "        elif 'fake' in relative_path.lower():\n",
    "            label = 'FAKE'\n",
    "        else:\n",
    "            label = 'unknown'\n",
    "        label_list.append(label)\n",
    "\n",
    "        # method (original/Deepfakes/FaceShifter/FaceSwap/NeuralTextures/Face2Face/unknown)\n",
    "        if 'original' in relative_path.lower():\n",
    "            method = 'original'\n",
    "        elif 'deepfakes' in relative_path.lower():\n",
    "            method = 'Deepfakes'\n",
    "        elif 'faceshifter' in relative_path.lower():\n",
    "            method = 'FaceShifter'\n",
    "        elif 'faceswap' in relative_path.lower():\n",
    "            method = 'FaceSwap'\n",
    "        elif 'neuraltextures' in relative_path.lower():\n",
    "            method = 'NeuralTextures'\n",
    "        elif 'face2face' in relative_path.lower():\n",
    "            method = 'Face2Face'\n",
    "        else:\n",
    "            method = 'others'\n",
    "        method_list.append(method)\n",
    "\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "        while success:\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 1 == 0:  # 매 5번째 프레임만 뽑아서 예측 (속도 + 대표성)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_tensor = transform(frame)\n",
    "                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (batch=1, seq_len=1, c=3, h, w)\n",
    "                input_tensor = input_tensor.to(device).float()\n",
    "\n",
    "                fmap, output_bin, output_method = model(input_tensor)\n",
    "                _, predicted_bin = torch.max(output_bin, 1)\n",
    "                _, predicted_method = torch.max(output_method, 1)\n",
    "\n",
    "                # 추가: threshold 기반 unknown 분류 처리\n",
    "                method_probs = torch.softmax(output_method.squeeze(0), dim=0)\n",
    "                method_confidence, method_class = torch.max(method_probs, dim=0)\n",
    "                threshold = 0.5  # ← 원하는 값으로 조절\n",
    "\n",
    "                if method_confidence < threshold:\n",
    "                    predicted_method = torch.tensor([6])  # unknown class\n",
    "                else:\n",
    "                    predicted_method = method_class.unsqueeze(0)  # 그대로 유지\n",
    "\n",
    "\n",
    "                score = torch.softmax(output_bin.squeeze(0), dim=0)[1].item()  # Real 확률만\n",
    "                frame_scores.append(score)\n",
    "\n",
    "                frame_preds.append(predicted_bin.item())\n",
    "                method_preds.append(predicted_method.item())\n",
    "                pooled = torch.mean(fmap.view(fmap.size(0), fmap.size(1), -1), dim=2)\n",
    "                pooled_features_per_video.append(pooled.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "            success, frame = cap.read()\n",
    "\n",
    "        # ⬇️ 프레임 평균을 비디오 feature로 저장\n",
    "        if pooled_features_per_video:\n",
    "            avg_feature = np.mean(pooled_features_per_video, axis=0)\n",
    "            video_feature_array.append(avg_feature)\n",
    "\n",
    "        if frame_scores:\n",
    "            video_bin_scores.append(np.mean(frame_scores))\n",
    "\n",
    "        cap.release()\n",
    "        final_prediction = 'Unknown' if len(frame_preds) == 0 else ('REAL' if round(sum(frame_preds)/len(frame_preds)) == 1 else 'FAKE')\n",
    "        majority_method = max(set(method_preds), key=method_preds.count) if method_preds else 6\n",
    "        method_pred_list.append(majority_method)\n",
    "\n",
    "        results.append({\n",
    "            'Filename': os.path.basename(video_path),\n",
    "            'Filepath': video_path,\n",
    "            'label': label,\n",
    "            'Prediction': final_prediction,\n",
    "            'method': method,  # 실제 method\n",
    "            'Predicted_method': majority_method  # 예측된 method\n",
    "        })\n",
    "\n",
    "# 결과 엑셀로 저장\n",
    "output_excel_path = f'{checkpoint_path}/(test)_{checkpoint_name}_predictions.xlsx'\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"✅ 모든 비디오 예측 결과가 엑셀로 저장되었습니다: {output_excel_path}\")\n",
    "\n",
    "y_true = label_list\n",
    "y_pred = [r['Prediction'] for r in results]\n",
    "true_bin = [0 if l == 'FAKE' else 1 for l in y_true]\n",
    "pred_bin = [0 if p == 'FAKE' else 1 for p in y_pred]\n",
    "method_dict = {'original': 0, 'Deepfakes': 1, 'FaceShifter': 2, 'FaceSwap': 3, 'NeuralTextures': 4, 'Face2Face': 5, 'others': 6}\n",
    "true_method = [method_dict.get(m, 6) for m in method_list]\n",
    "pred_method = method_pred_list\n",
    "\n",
    "print(\"\\n================ Test Report ================\")\n",
    "print_confusion_matrix(true_bin, pred_bin)\n",
    "print_confusion_matrix_method(true_method, pred_method)\n",
    "\n",
    "# ✅ ROC Curve 및 t-SNE 시각화\n",
    "plot_roc_curve(torch.tensor(true_bin), torch.tensor(video_bin_scores), checkpoint_path, f\"{checkpoint_name}\")\n",
    "plot_tsne(np.array(video_feature_array), true_method, checkpoint_path, f\"{checkpoint_name}\",\n",
    "          method_labels=['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face', 'others'])\n",
    "plot_tsne_binary(np.array(video_feature_array), np.array(pred_bin), checkpoint_path, f\"{checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXcy769nAuj6"
   },
   "source": [
    "## CELEB-DF test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH18rfi5AuBx"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 코랩 서버import sys\n",
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "checkpoint_name=\"checkpoint_v33\"\n",
    "\n",
    "test_input_file_path='/content/drive/MyDrive/Capstone/Dataset/celeb-df/*'\n",
    "# test_input_file_path2='/content/drive/MyDrive/Capstone/Dataset/DFDC/test/*/*'\n",
    "# test_input_file_path3='/content/drive/MyDrive/Capstone/Dataset/celeb-df/test/*/*'\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/celeb-df'\n",
    "base_path = '/content/drive/MyDrive/Capstone/Dataset'  # 상대 주소 찾기 위해 base_path 제거\n",
    "frames=150\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"Dataset: CELEB-DF\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print()\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "#Model with feature visualization\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           #  model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "           #  self.model = model.extract_features\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()    # 이거는 넣고 빼고 실험해보래\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        # self.linear1 = nn.Linear(hidden_dim,num_classes) # hidden_dim 변수로 넣어줌\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # 두 개의 출력: 이진 분류와 method 분류\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        # return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "# 디바이스 설정\n",
    "device = get_device()\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "\n",
    "# 모델 구조를 다시 정의\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "model.load_state_dict(torch.load(f'{checkpoint_path}/{checkpoint_name}.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Output confusion matrix   성능 평가\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix  #내가 추가함\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Output confusion matrix / 모델 성능 평가\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'로 정수 표현\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(test_celebdf).png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # 성능 출력\n",
    "    print(\"📊 Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\n📈 Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    pred_score = output_bin.cpu().numpy()  # Real 확률\n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve(test_celebdf).png\")\n",
    "    print(f\"✅ ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve(test_celebdf).png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#2. to load preprocessod video to memory / 전처리된 영상 가져오기\n",
    "new_video_files =  glob.glob(f'{test_input_file_path}/*.mp4')\n",
    "\n",
    "random.shuffle(new_video_files)\n",
    "\n",
    "# ✅ 결과 저장 리스트 초기화\n",
    "method_pred_list = []  # ROC Curve 용\n",
    "video_bin_scores = []   # t-SNE 시각화용\n",
    "\n",
    "# ✅ 결과 저장 리스트 초기화\n",
    "results = []\n",
    "label_list = []\n",
    "folder_path_list = []\n",
    "method_list = []\n",
    "\n",
    "\n",
    "video_feature_array = []\n",
    "with torch.no_grad():\n",
    "    for video_path in tqdm(new_video_files):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_preds = []\n",
    "        method_preds=[]\n",
    "        pooled_features_per_video = []\n",
    "        frame_scores = []\n",
    "\n",
    "        frame_idx = 0\n",
    "\n",
    "        relative_path = os.path.relpath(video_path,base_path).replace(\"\\\\\", \"/\")\n",
    "        folder_path_list.append(relative_path)\n",
    "\n",
    "        # label (real/fake)\n",
    "        if 'real' in relative_path.lower():\n",
    "            label = 'REAL'\n",
    "        elif 'fake' in relative_path.lower():\n",
    "            label = 'FAKE'\n",
    "        else:\n",
    "            label = 'unknown'\n",
    "        label_list.append(label)\n",
    "\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "        while success:\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 1 == 0:  # 매 5번째 프레임만 뽑아서 예측 (속도 + 대표성)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_tensor = transform(frame)\n",
    "                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (batch=1, seq_len=1, c=3, h, w)\n",
    "                input_tensor = input_tensor.to(device).float()\n",
    "\n",
    "                fmap, output_bin, output_method = model(input_tensor)\n",
    "                _, predicted_bin = torch.max(output_bin, 1)\n",
    "                _, predicted_method = torch.max(output_method, 1)\n",
    "\n",
    "                # 추가: threshold 기반 unknown 분류 처리\n",
    "                method_probs = torch.softmax(output_method.squeeze(0), dim=0)\n",
    "                method_confidence, method_class = torch.max(method_probs, dim=0)\n",
    "                threshold = 0.5  # ← 원하는 값으로 조절\n",
    "\n",
    "                if method_confidence < threshold:\n",
    "                    predicted_method = torch.tensor([6])  # unknown class\n",
    "                else:\n",
    "                    predicted_method = method_class.unsqueeze(0)  # 그대로 유지\n",
    "\n",
    "\n",
    "                score = torch.softmax(output_bin.squeeze(0), dim=0)[1].item()  # Real 확률만\n",
    "                frame_scores.append(score)\n",
    "\n",
    "                frame_preds.append(predicted_bin.item())\n",
    "                method_preds.append(predicted_method.item())\n",
    "\n",
    "                pooled = torch.mean(fmap.view(fmap.size(0), fmap.size(1), -1), dim=2)\n",
    "                pooled_features_per_video.append(pooled.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "            success, frame = cap.read()\n",
    "\n",
    "        # ⬇️ 프레임 평균을 비디오 feature로 저장\n",
    "        if pooled_features_per_video:\n",
    "            avg_feature = np.mean(pooled_features_per_video, axis=0)\n",
    "            video_feature_array.append(avg_feature)\n",
    "\n",
    "        if frame_scores:\n",
    "            video_bin_scores.append(np.mean(frame_scores))\n",
    "\n",
    "        cap.release()\n",
    "        final_prediction = 'Unknown' if len(frame_preds) == 0 else ('REAL' if round(sum(frame_preds)/len(frame_preds)) == 1 else 'FAKE')\n",
    "        majority_method = max(set(method_preds), key=method_preds.count) if method_preds else 6\n",
    "        method_pred_list.append(majority_method)\n",
    "\n",
    "        results.append({\n",
    "            'Filename': os.path.basename(video_path),\n",
    "            'Filepath': video_path,\n",
    "            'label': label,\n",
    "            'Prediction': final_prediction,\n",
    "            # 'method': method,  # 실제 method\n",
    "            'Predicted_method': majority_method  # 예측된 method\n",
    "        })\n",
    "\n",
    "# 결과 엑셀로 저장\n",
    "output_excel_path = f'{checkpoint_path}/(test)_{checkpoint_name}_predictions_celebdf.xlsx'\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"✅ 모든 비디오 예측 결과가 엑셀로 저장되었습니다: {output_excel_path}\")\n",
    "\n",
    "y_true = label_list\n",
    "y_pred = [r['Prediction'] for r in results]\n",
    "true_bin = [0 if l == 'FAKE' else 1 for l in y_true]\n",
    "pred_bin = [0 if p == 'FAKE' else 1 for p in y_pred]\n",
    "pred_method = method_pred_list\n",
    "\n",
    "print(\"\\n================ Test Report ================\")\n",
    "print_confusion_matrix(true_bin, pred_bin)\n",
    "\n",
    "# ✅ ROC Curve\n",
    "plot_roc_curve(torch.tensor(true_bin), torch.tensor(video_bin_scores), checkpoint_path, f\"{checkpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_wqHU33pnQH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def compute_eer(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "    return fpr[eer_idx], thresholds[eer_idx]\n",
    "\n",
    "def compute_pauc(y_true, y_scores, fpr_limit=0.1):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    mask = fpr <= fpr_limit\n",
    "    return auc(fpr[mask], tpr[mask]) / fpr_limit\n",
    "\n",
    "\n",
    "# FAKE를 positive class (1)로 보기 위해 점수 뒤집기\n",
    "video_fake_scores = [1 - s for s in video_bin_scores]\n",
    "true_bin = [1 if l == 'FAKE' else 0 for l in y_true]\n",
    "\n",
    "# AUC / EER / pAUC 계산\n",
    "auc_val = roc_auc_score(true_bin, video_fake_scores)\n",
    "eer, eer_threshold = compute_eer(true_bin, video_fake_scores)\n",
    "pauc = compute_pauc(true_bin, video_fake_scores)\n",
    "\n",
    "# 출력\n",
    "print(f\"AUC (FAKE=1 기준): {auc_val:.4f}\")\n",
    "print(f\"EER (FAKE=1 기준): {eer:.4f} at threshold {eer_threshold:.4f}\")\n",
    "print(f\"pAUC@0.1 (FAKE=1 기준): {pauc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUFAga0_Eku-"
   },
   "source": [
    "### DeeperForencis test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpeql_xHEgk6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 코랩 서버import sys\n",
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "checkpoint_name=\"checkpoint_v33\"\n",
    "\n",
    "test_input_file_path='/content/drive/MyDrive/Capstone/Dataset/DeeperForensics/*'\n",
    "# test_input_file_path2='/content/drive/MyDrive/Capstone/Dataset/DFDC/test/*/*'\n",
    "# test_input_file_path3='/content/drive/MyDrive/Capstone/Dataset/celeb-df/test/*/*'\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/DeeperForensics'\n",
    "base_path = '/content/drive/MyDrive/Capstone/Dataset'  # 상대 주소 찾기 위해 base_path 제거\n",
    "frames=150\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"Dataset: DeeperForensics\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print()\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "#Model with feature visualization\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           #  model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "           #  self.model = model.extract_features\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()    # 이거는 넣고 빼고 실험해보래\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        # self.linear1 = nn.Linear(hidden_dim,num_classes) # hidden_dim 변수로 넣어줌\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # 두 개의 출력: 이진 분류와 method 분류\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        # return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "# 디바이스 설정\n",
    "device = get_device()\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "\n",
    "# 모델 구조를 다시 정의\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "model.load_state_dict(torch.load(f'{checkpoint_path}/{checkpoint_name}.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Output confusion matrix   성능 평가\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix  #내가 추가함\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Output confusion matrix / 모델 성능 평가\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'로 정수 표현\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(test_deeperforencis).png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # 성능 출력\n",
    "    print(\"📊 Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\n📈 Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    pred_score = output_bin.cpu().numpy()  # Real 확률\n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve(test_deeperforenciss).png\")\n",
    "    print(f\"✅ ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve(test_deeperforencis).png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#2. to load preprocessod video to memory / 전처리된 영상 가져오기\n",
    "new_video_files =  glob.glob(f'{test_input_file_path}/*.mp4')\n",
    "\n",
    "random.shuffle(new_video_files)\n",
    "\n",
    "# ✅ 결과 저장 리스트 초기화\n",
    "method_pred_list = []  # ROC Curve 용\n",
    "video_bin_scores = []   # t-SNE 시각화용\n",
    "\n",
    "# ✅ 결과 저장 리스트 초기화\n",
    "results = []\n",
    "label_list = []\n",
    "folder_path_list = []\n",
    "method_list = []\n",
    "\n",
    "\n",
    "video_feature_array = []\n",
    "with torch.no_grad():\n",
    "    for video_path in tqdm(new_video_files):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_preds = []\n",
    "        method_preds=[]\n",
    "        pooled_features_per_video = []\n",
    "        frame_scores = []\n",
    "\n",
    "        frame_idx = 0\n",
    "\n",
    "        relative_path = os.path.relpath(video_path,base_path).replace(\"\\\\\", \"/\")\n",
    "        folder_path_list.append(relative_path)\n",
    "\n",
    "        # label (real/fake)\n",
    "        if 'real' in relative_path.lower():\n",
    "            label = 'REAL'\n",
    "        elif 'fake' in relative_path.lower():\n",
    "            label = 'FAKE'\n",
    "        else:\n",
    "            label = 'unknown'\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "        while success:\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 1 == 0:  # 매 5번째 프레임만 뽑아서 예측 (속도 + 대표성)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_tensor = transform(frame)\n",
    "                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (batch=1, seq_len=1, c=3, h, w)\n",
    "                input_tensor = input_tensor.to(device).float()\n",
    "\n",
    "                fmap, output_bin, output_method = model(input_tensor)\n",
    "                _, predicted_bin = torch.max(output_bin, 1)\n",
    "                _, predicted_method = torch.max(output_method, 1)\n",
    "\n",
    "                # 추가: threshold 기반 unknown 분류 처리\n",
    "                method_probs = torch.softmax(output_method.squeeze(0), dim=0)\n",
    "                method_confidence, method_class = torch.max(method_probs, dim=0)\n",
    "                threshold = 0.5  # ← 원하는 값으로 조절\n",
    "\n",
    "                if method_confidence < threshold:\n",
    "                    predicted_method = torch.tensor([6])  # unknown class\n",
    "                else:\n",
    "                    predicted_method = method_class.unsqueeze(0)  # 그대로 유지\n",
    "\n",
    "                score = torch.softmax(output_bin.squeeze(0), dim=0)[1].item()  # Real 확률만\n",
    "                frame_scores.append(score)\n",
    "\n",
    "                frame_preds.append(predicted_bin.item())\n",
    "                method_preds.append(predicted_method.item())\n",
    "\n",
    "                pooled = torch.mean(fmap.view(fmap.size(0), fmap.size(1), -1), dim=2)\n",
    "                pooled_features_per_video.append(pooled.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "            success, frame = cap.read()\n",
    "\n",
    "        # ⬇️ 프레임 평균을 비디오 feature로 저장\n",
    "        if pooled_features_per_video:\n",
    "            avg_feature = np.mean(pooled_features_per_video, axis=0)\n",
    "            video_feature_array.append(avg_feature)\n",
    "\n",
    "        if frame_scores:\n",
    "            video_bin_scores.append(np.mean(frame_scores))\n",
    "\n",
    "        cap.release()\n",
    "        final_prediction = 'Unknown' if len(frame_preds) == 0 else ('REAL' if round(sum(frame_preds)/len(frame_preds)) == 1 else 'FAKE')\n",
    "        majority_method = max(set(method_preds), key=method_preds.count) if method_preds else 6\n",
    "        method_pred_list.append(majority_method)\n",
    "\n",
    "        results.append({\n",
    "            'Filename': os.path.basename(video_path),\n",
    "            'Filepath': video_path,\n",
    "            'label': label,\n",
    "            'Prediction': final_prediction,\n",
    "            # 'method': method,  # 실제 method\n",
    "            'Predicted_method': majority_method  # 예측된 method\n",
    "        })\n",
    "\n",
    "# 결과 엑셀로 저장\n",
    "output_excel_path = f'{checkpoint_path}/(test)_{checkpoint_name}_predictions_deeperforencis.xlsx'\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"✅ 모든 비디오 예측 결과가 엑셀로 저장되었습니다: {output_excel_path}\")\n",
    "\n",
    "y_true = label_list\n",
    "y_pred = [r['Prediction'] for r in results]\n",
    "true_bin = [0 if l == 'FAKE' else 1 for l in y_true]\n",
    "pred_bin = [0 if p == 'FAKE' else 1 for p in y_pred]\n",
    "pred_method = method_pred_list\n",
    "\n",
    "print(\"\\n================ Test Report ================\")\n",
    "print_confusion_matrix(true_bin, pred_bin)\n",
    "# print_confusion_matrix_method(true_method, pred_method)\n",
    "\n",
    "# ✅ ROC Curve 및 t-SNE 시각화\n",
    "plot_roc_curve(torch.tensor(true_bin), torch.tensor(video_bin_scores), checkpoint_path, f\"{checkpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_KI7nWsEp26"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def compute_eer(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "    return fpr[eer_idx], thresholds[eer_idx]\n",
    "\n",
    "def compute_pauc(y_true, y_scores, fpr_limit=0.1):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    mask = fpr <= fpr_limit\n",
    "    return auc(fpr[mask], tpr[mask]) / fpr_limit\n",
    "\n",
    "\n",
    "# FAKE를 positive class (1)로 보기 위해 점수 뒤집기\n",
    "video_fake_scores = [1 - s for s in video_bin_scores]\n",
    "true_bin = [1 if l == 'FAKE' else 0 for l in y_true]\n",
    "\n",
    "# AUC / EER / pAUC 계산\n",
    "auc_val = roc_auc_score(true_bin, video_fake_scores)\n",
    "eer, eer_threshold = compute_eer(true_bin, video_fake_scores)\n",
    "pauc = compute_pauc(true_bin, video_fake_scores)\n",
    "\n",
    "# 출력\n",
    "print(f\"AUC (FAKE=1 기준): {auc_val:.4f}\")\n",
    "print(f\"EER (FAKE=1 기준): {eer:.4f} at threshold {eer_threshold:.4f}\")\n",
    "print(f\"pAUC@0.1 (FAKE=1 기준): {pauc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzH84v0rz/jVmTZkJUBesI",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
