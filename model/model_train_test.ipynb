{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDvwC4EREIbq"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds21w9F6PkHc"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBUsl72t-dMd"
   },
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAgV--qT0bis"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "input_file_path='/content/drive/MyDrive/Capstone/Dataset/ff++/train/*/*'\n",
    "base_path='/content/drive/MyDrive/Capstone/Dataset/'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/ff++'\n",
    "\n",
    "num_epochs=30 # ì—í­ íšŸìˆ˜\n",
    "checkpoint_name=\"checkpoint_v33\" # ì²´í¬í¬ì¸íŠ¸ ì´ë¦„\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "frames=150\n",
    "\n",
    "\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"model_name : {selected_model}\")\n",
    "print(f\"Dataset : FaceForencis++\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print(f\"Training for {num_epochs} epochs\")\n",
    "print()\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import face_recognition\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import seaborn as sn\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import timm\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from sklearn.metrics import confusion_matrix  #ë‚´ê°€ ì¶”ê°€í•¨\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# device / ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(f\"âœ… Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. load the video name and labels from csv / metadataì—ì„œ real/fake ì—¬ë¶€ ê°€ì ¸ì˜¤ê¸°\n",
    "class video_dataset(Dataset):\n",
    "    def __init__(self,video_names,labels,sequence_length = 60,transform = None):\n",
    "        self.video_names = video_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "    def __getitem__(self,idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        # a = int(100/self.count)\n",
    "        # first_frame = np.random.randint(0,a)\n",
    "        temp_video = video_path.split('/')[-1]\n",
    "        label = self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
    "        if(label == 'FAKE'):\n",
    "          label = 0\n",
    "        if(label == 'REAL'):\n",
    "          label = 1\n",
    "\n",
    "        method_str= self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),2]\n",
    "\n",
    "        # methodë¥¼ ìˆ«ì ë¼ë²¨ë¡œ ë§¤í•‘\n",
    "        method_dict = {'original': 0, 'Deepfakes': 1, 'FaceShifter': 2, 'FaceSwap': 3, 'NeuralTextures': 4, 'Face2Face':5, 'others': 6 }\n",
    "        method = method_dict[method_str]\n",
    "\n",
    "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
    "          frames.append(self.transform(frame))\n",
    "          if(len(frames) == self.count):\n",
    "            break\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]\n",
    "        return frames,label,method\n",
    "\n",
    "    def frame_extract(self,path):\n",
    "      vidObj = cv2.VideoCapture(path)\n",
    "      success = 1\n",
    "      while success:\n",
    "          success, image = vidObj.read()\n",
    "          if success:\n",
    "              yield image\n",
    "\n",
    "# count the number of fake and real videos / real fake ì˜ìƒ ê°œìˆ˜ ì„¸ê¸°\n",
    "def number_of_real_and_fake_videos(data_list):\n",
    "  header_list = [\"file\",\"label\",\"method\"]\n",
    "  lab = pd.read_csv(f'{meta_data_path}/Global_metadata.csv',names=header_list)\n",
    "  fake = 0\n",
    "  real = 0\n",
    "  original=0\n",
    "  deepfakes=0\n",
    "  faceshifter=0\n",
    "  faceswap=0\n",
    "  neuraltextures=0\n",
    "  face2face=0\n",
    "  others=0\n",
    "  for i in data_list:\n",
    "    temp_video = i.split('/')[-1]\n",
    "    label = lab.iloc[(lab.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
    "    if(label == 'FAKE'):\n",
    "      fake+=1\n",
    "    if(label == 'REAL'):\n",
    "      real+=1\n",
    "    method = lab.iloc[(lab.loc[labels[\"file\"] == temp_video].index.values[0]),2]\n",
    "    method = method.lower()\n",
    "    if(method == 'original'):\n",
    "      original+=1\n",
    "    elif(method == 'deepfakes'):\n",
    "      deepfakes+=1\n",
    "    elif(method == 'faceshifter'):\n",
    "      faceshifter+=1\n",
    "    elif(method == 'faceswap'):\n",
    "      faceswap+=1\n",
    "    elif(method == 'neuraltextures'):\n",
    "      neuraltextures+=1\n",
    "    elif(method == 'face2face'):\n",
    "      face2face+=1\n",
    "    else:\n",
    "       others+=1\n",
    "\n",
    "\n",
    "  return real,fake,original, deepfakes,faceshifter, faceswap, neuraltextures,face2face, others\n",
    "\n",
    "\n",
    "# load the labels and video in data loader\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#2. to load preprocessod video to memory / ì „ì²˜ë¦¬ëœ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°\n",
    "video_files = sorted(glob.glob(f'{input_file_path}/*.mp4'))\n",
    "# random.shuffle(video_files)\n",
    "\n",
    "header_list = [\"file\",\"label\",\"method\"]\n",
    "labels = pd.read_csv(f'{meta_data_path}/Global_metadata.csv',names=header_list)\n",
    "\n",
    "# train_videos = video_files[:int(0.9*len(video_files))]  # 8:2ìœ¼ë¡œ train:test\n",
    "# valid_videos = video_files[int(0.9*len(video_files)):]\n",
    "train_videos, valid_videos = train_test_split(video_files, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"train : \" , len(train_videos))\n",
    "print(\"Validation : \" , len(valid_videos))\n",
    "\n",
    "train_count=number_of_real_and_fake_videos(train_videos)\n",
    "test_count=number_of_real_and_fake_videos(valid_videos)\n",
    "print(f\"TRAIN:  Real: {train_count[0]} Fake: {train_count[1]} original : {train_count[2]} Deepfakes : {train_count[3]}\",\n",
    "      f\"FaceShifter : {train_count[4]}  FaceSwap : {train_count[5]} NeuralTextures : {train_count[6]} Face2Face {train_count[7]} others : {train_count[8]}\")\n",
    "print(f\"VALIDATION:  Real: {test_count[0]} Fake: {test_count[1]} original : {test_count[2]} Deepfakes : {test_count[3]}\",\n",
    "      f\"FaceShifter : {test_count[4]}  FaceSwap : {test_count[5]} NeuralTextures : {test_count[6]} Face2Face {test_count[7]} others : {test_count[8]}\")\n",
    "im_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "train_data = video_dataset(train_videos,labels,sequence_length = 10,transform = train_transforms)\n",
    "#print(train_data)\n",
    "val_data = video_dataset(valid_videos,labels,sequence_length = 10,transform = test_transforms)\n",
    "\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "  train_loader = DataLoader(train_data,batch_size = 8,shuffle = True,num_workers = 2,pin_memory=True)\n",
    "  valid_loader = DataLoader(val_data,batch_size = 8,shuffle = True,num_workers = 2,pin_memory=True)\n",
    "else:\n",
    "# cpuì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ë³‘ë ¬ì²˜ë¦¬ ë»„\n",
    "  train_loader = DataLoader(train_data,batch_size = 16,shuffle = True,num_workers = 0)  # ì—¬ê¸°ì„œ batch size ì¡°ì • (í•œë²ˆì— ëª‡ê°œì˜ ë°ì´í„°ë¥¼ ë¬¶ì–´ì„œ í•™ìŠµí• ì§€, batchê°œìˆ˜=ë°ì´í„° ìˆ˜/batch size)\n",
    "  valid_loader = DataLoader(val_data,batch_size = 16,shuffle = True,num_workers = 0)\n",
    "\n",
    "#Model with feature visualization\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()   \n",
    "        self.dp = nn.Dropout(0.5)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # ë‘ ê°œì˜ ì¶œë ¥: ì´ì§„ ë¶„ë¥˜ì™€ method ë¶„ë¥˜\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "\n",
    "# ëª¨ë¸ì„ deviceë¡œ ë³´ë‚´ê¸°\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "input_tensor = torch.from_numpy(np.empty((1, 20, 3, 224,224))).type(torch.FloatTensor).to(device)\n",
    "\n",
    "# ëª¨ë¸ ì‹¤í–‰\n",
    "fmap, output_bin, output_method = model(input_tensor)\n",
    "\n",
    "\n",
    "def train_epoch(epoch, num_epochs, data_loader, model, criterion_bin, criterion_method, optimizer):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    t = []\n",
    "\n",
    "    for i, (inputs,targets_bin, targets_method) in enumerate(data_loader):\n",
    "        # GPUì—ì„œ ì‹¤í–‰\n",
    "        # inputs, targets deviceë¡œ ì˜¬ë¦¬ê¸°\n",
    "        inputs = inputs.to(device)\n",
    "        targets_bin = targets_bin.to(device)\n",
    "        targets_method = targets_method.to(device)\n",
    "\n",
    "        _, output_bin, output_method = model(inputs)\n",
    "        # gpuì—ì„œ ì‹¤í–‰\n",
    "        loss_bin = criterion_bin(output_bin, targets_bin)\n",
    "        loss_method = criterion_method(output_method, targets_method)\n",
    "        loss = loss_bin + loss_method\n",
    "\n",
    "        acc = calculate_accuracy(output_bin, targets_bin)\n",
    "        acc_method = calculate_accuracy(output_method, targets_method)\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        accuracies.update(acc, inputs.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%, Acc(method): %.2f%%]\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    num_epochs,\n",
    "                    i,\n",
    "                    len(data_loader),\n",
    "                    losses.avg,\n",
    "                    accuracies.avg,\n",
    "                    acc_method,\n",
    "                    ))\n",
    "\n",
    "    # save the model / ëª¨ë¸ ì €ì¥\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), f'{checkpoint_path}/{checkpoint_name}.pt')\n",
    "\n",
    "    return losses.avg,accuracies.avg,acc_method\n",
    "\n",
    "def test(epoch,model, data_loader ,criterion_bin, criterion_method):\n",
    "    print('Testing')\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    pred_bin= []\n",
    "    true_bin= []\n",
    "    pred_method = []\n",
    "    true_method = []\n",
    "    output_bin_all = [] # for ROC\n",
    "    feature_list = [] # for t-SNE\n",
    "\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets_bin, targets_method) in enumerate(data_loader):\n",
    "            model = model.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            targets_bin = targets_bin.to(device)\n",
    "            targets_method = targets_method.to(device)\n",
    "\n",
    "\n",
    "            fmap, output_bin, output_method = model(inputs)\n",
    "            batch_size, seq_length = inputs.shape[0], inputs.shape[1]\n",
    "            features = fmap.view(batch_size, seq_length, -1).mean(dim=1)# í‰ê·  pooling\n",
    "            feature_list.append(features.cpu().numpy())\n",
    "            output_bin_all.append(output_bin.detach().cpu())\n",
    "            # GPu cuda ì‚¬ìš©\n",
    "            loss_bin = criterion_bin(output_bin, targets_bin)\n",
    "            loss_method = criterion_method(output_method, targets_method)\n",
    "            loss = loss_bin + loss_method\n",
    "\n",
    "            acc = calculate_accuracy(output_bin, targets_bin)\n",
    "            acc_method = calculate_accuracy(output_method, targets_method)\n",
    "            #\n",
    "            _, p_bin = torch.max(output_bin, 1)\n",
    "            _, p_method = torch.max(output_method, 1)\n",
    "            true_bin += targets_bin.cpu().numpy().tolist()\n",
    "            pred_bin += p_bin.cpu().numpy().tolist()\n",
    "            true_method += targets_method.cpu().numpy().tolist()\n",
    "            pred_method += p_method.cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            accuracies.update(acc, inputs.size(0))\n",
    "            sys.stdout.write(\n",
    "                    \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%, Acc(method): %.2f%%]\"\n",
    "                    % (\n",
    "                        i,\n",
    "                        len(data_loader),\n",
    "                        losses.avg,\n",
    "                        accuracies.avg,\n",
    "                        acc_method,\n",
    "                        )\n",
    "                    )\n",
    "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
    "\n",
    "    output_bin_all = torch.cat(output_bin_all, dim=0)  # [N, 2] í˜•íƒœë¡œ ë§Œë“¦\n",
    "    feature_array = np.concatenate(feature_list, axis=0)  # [N, D] í˜•íƒœ\n",
    "    return true_bin, pred_bin, true_method, pred_method,losses.avg,accuracies.avg,acc_method,output_bin_all,feature_array\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def calculate_accuracy(outputs, targets): # top-1 accuracy\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "    return 100* n_correct_elems / batch_size\n",
    "\n",
    "#Output confusion matrix / ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'ë¡œ ì •ìˆ˜ í‘œí˜„\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    # plt.show()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot.png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # ì„±ëŠ¥ ì¶œë ¥\n",
    "    print(\"ğŸ“Š Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "def print_confusion_matrix_method(y_true_method, y_pred_method):\n",
    "\n",
    "    labels = ['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face','others']\n",
    "    label_indices = list(range(len(labels))) # [0, 1, 2, ..., 6]\n",
    "    cm = confusion_matrix(y_true_method, y_pred_method, labels=label_indices)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Blues')\n",
    "    plt.ylabel('Actual label', size=16)\n",
    "    plt.xlabel('Predicted label', size=16)\n",
    "    plt.xticks(np.arange(len(labels)) + 0.5, labels, rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(np.arange(len(labels)) + 0.5, labels, rotation=0, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(method).png')\n",
    "\n",
    "    # ì •í™•ë„ ê³„ì‚°: ëª¨ë“  ì •ë‹µ ì˜ˆì¸¡ ìˆ˜ / ì „ì²´ ìƒ˜í”Œ ìˆ˜\n",
    "    correct_preds = np.trace(cm)\n",
    "    total_preds = np.sum(cm)\n",
    "    calculated_acc = correct_preds / total_preds\n",
    "    print(f\"\\nâœ… Calculated Accuracy: {calculated_acc * 100:.2f}%\")\n",
    "\n",
    "    # ì„±ëŠ¥ ì¶œë ¥\n",
    "    print(\"ğŸ“Š Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "    print(classification_report(y_true_method, y_pred_method, target_names=labels, labels=label_indices))\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    \"\"\"\n",
    "    ROC Curveë¥¼ ê·¸ë¦¬ê³  ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Parameters:\n",
    "        - true_bin: List[int], ì‹¤ì œ ë ˆì´ë¸” (0=Fake, 1=Real)\n",
    "        - output_bin: Tensor[N, 2], ëª¨ë¸ì˜ softmax ì „ ì´ì§„ ë¶„ë¥˜ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    pred_score = torch.softmax(output_bin, dim=1)[:, 1].cpu().numpy()  # Real í™•ë¥ \n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'âœ… ROC curve (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve.png\")\n",
    "    print(f\"âœ… ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve.png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(features, labels, checkpoint_path, checkpoint_name, method_labels=None):\n",
    "    \"\"\"\n",
    "    t-SNEë¥¼ ì´ìš©í•œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Parameters:\n",
    "        - features: List or np.ndarray, (N, D) CNN or LSTM feature vectors\n",
    "        - labels: List[int], (N,) í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (ex. 0~5)\n",
    "        - checkpoint_path: ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "        - checkpoint_name: ì €ì¥ íŒŒì¼ ì´ë¦„ ì ‘ë‘ì‚¬\n",
    "        - method_labels: List[str], ê° í´ë˜ìŠ¤ì— ëŒ€ì‘ë˜ëŠ” ë¬¸ìì—´ ë ˆì´ë¸”(optional)\n",
    "    \"\"\"\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, max(5, n_samples // 3))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_classes = np.unique(labels)\n",
    "    for cls in unique_classes:\n",
    "        idx = labels == cls\n",
    "        label_name = method_labels[cls] if method_labels and cls < len(method_labels) else str(cls)\n",
    "        plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=label_name, alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Method Class Features')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_tsne.png\")\n",
    "    print(f\"âœ… t-SNE plot saved to {checkpoint_path}/{checkpoint_name}_tsne.png\")\n",
    "\n",
    "\n",
    "# loss ê·¸ë˜í”„\n",
    "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
    "  loss_train = train_loss_avg\n",
    "  loss_val = test_loss_avg\n",
    "  print(num_epochs)\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.clf()  # Clear the previous figure\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "  plt.title('Training and Validation loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  # plt.show()\n",
    "  plt.savefig(f'{checkpoint_path}/{checkpoint_name}_loss_plot.png')\n",
    "\n",
    "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
    "  loss_train = train_accuracy\n",
    "  loss_val = test_accuracy\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.clf()  # Clear the previous figure\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "  plt.title('Training and Validation accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  # plt.show()\n",
    "  plt.savefig(f'{checkpoint_path}/{checkpoint_name}_accuracy_plot.png')\n",
    "\n",
    "\n",
    "\n",
    "#learning rate\n",
    "lr = 1e-4             #ì‹œì‘ 1e-5#0.001\n",
    "#number of epochs (ë§¨ ìœ„ì—ì„œ ì„¤ì •)\n",
    "#num_epochs = 2\n",
    "\n",
    "# criterion_bin = nn.CrossEntropyLoss().to(device)\n",
    "weights = torch.tensor([0.7,1.75]).to(device)  # [fake, real]ì˜ ìˆœì„œë¼ê³  ê°€ì •\n",
    "criterion_bin = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "criterion_method = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= lr,weight_decay = 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ”§ ReduceLROnPlateau ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ë©´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "checkpoint_file = f'{checkpoint_path}/{checkpoint_name}.pt'\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])  # ì¶”ê°€\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í•™ìŠµ ì¬ê°œ: Epoch {start_epoch}ë¶€í„°\")\n",
    "    train_loss_avg = checkpoint['train_loss']\n",
    "    train_accuracy = checkpoint['train_acc']\n",
    "    test_loss_avg = checkpoint['val_loss']\n",
    "    test_accuracy = checkpoint['val_acc']\n",
    "    best_auc = checkpoint['best_auc']\n",
    "\n",
    "else:\n",
    "    print(\"ğŸš¨ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ì–´ ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "    start_epoch = 1\n",
    "    train_loss_avg, train_accuracy = [], []\n",
    "    test_loss_avg, test_accuracy = [], []\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "    print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "\n",
    "best_auc = 0.0\n",
    "best_epoch=0\n",
    "best_model_path = f\"{checkpoint_path}/{checkpoint_name}_best.pt\"\n",
    "\n",
    "# ì‹œê°„ ì¸¡ì • ì‹œì‘\n",
    "start_time = time.time()\n",
    "for epoch in range(start_epoch, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    l, acc ,m_acc= train_epoch(epoch,num_epochs,train_loader,model,criterion_bin, criterion_method,optimizer)\n",
    "    train_loss_avg.append(l)\n",
    "    train_accuracy.append(acc)\n",
    "    true_bin, pred_bin, true_method, pred_method, tl, t_acc, m_acc,output_bin_all,feature_array= test(epoch,model,valid_loader,criterion_bin, criterion_method)\n",
    "    test_loss_avg.append(tl)\n",
    "    test_accuracy.append(t_acc)\n",
    "\n",
    "    # ğŸ”§ ReduceLROnPlateau ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰\n",
    "    scheduler.step(tl)\n",
    "\n",
    "    # í˜„ì¬ learning rate í™•ì¸\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"ğŸ“‰ í˜„ì¬ Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_elapsed = epoch_end_time - epoch_start_time\n",
    "    print(f\"âœ… Epoch {epoch} ì†Œìš” ì‹œê°„: {epoch_elapsed:.2f}ì´ˆ\")\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),  # ì¶”ê°€\n",
    "        'train_loss': train_loss_avg,\n",
    "        'train_acc': train_accuracy,\n",
    "        'val_loss': test_loss_avg,\n",
    "        'val_acc': test_accuracy,\n",
    "        'best_auc':best_auc\n",
    "    }, checkpoint_file)\n",
    "\n",
    "    # AUC ê³„ì‚°\n",
    "    pred_score = torch.softmax(output_bin_all, dim=1)[:, 1].cpu().numpy()\n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"ğŸ¯ AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ìœ¼ë©´ ë”°ë¡œ ì €ì¥\n",
    "    if roc_auc > best_auc:\n",
    "      best_auc = roc_auc\n",
    "      best_epoch=epoch\n",
    "      torch.save(model.state_dict(), best_model_path)\n",
    "      print(f\"ğŸŒŸ Best ëª¨ë¸ ì €ì¥ë¨ ({epoch} epochì—ì„œ AUC={roc_auc:.4f}): {best_model_path}\")\n",
    "\n",
    "      print(confusion_matrix(true_bin,pred_bin)) #confusion_matrix(ì´ì§„ ë¶„ë¥˜)\n",
    "      print(confusion_matrix(true_method, pred_method))  #confusion_matrix(ë‹¤ì¤‘ ë¶„ë¥˜)\n",
    "      plot_roc_curve(true_bin, output_bin_all, checkpoint_path, f\"{checkpoint_name}_best_point\") # ROC Curve (ì´ì§„ ë¶„ë¥˜)\n",
    "      plot_tsne(feature_array, true_method, checkpoint_path, f\"{checkpoint_name}_best_point\",    # t-SNE (ë‹¤ì¤‘ ë¶„ë¥˜)\n",
    "                method_labels=['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face', 'others'])\n",
    "\n",
    "    if epoch%5==0:\n",
    "      plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
    "      plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ì‹œê°„ ì¸¡ì • ë\n",
    "end_time = time.time()\n",
    "\n",
    "plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
    "plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
    "print(confusion_matrix(true_bin,pred_bin))\n",
    "elapsed_time = end_time - start_time\n",
    "# aucê°’\n",
    "pred_score = torch.softmax(output_bin_all, dim=1)[:, 1].cpu().numpy()  # Real í™•ë¥ \n",
    "fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'âœ… ROC curve (AUC = {roc_auc:.4f})')\n",
    "print(f\"âœ… ì „ì²´ í•™ìŠµ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ\")\n",
    "\n",
    "print(\"--------------------------------------------------------Report---------------------------------------------\")\n",
    "print(f\"âœ… Using device: {device}\")\n",
    "print(f\"âœ… ì „ì²´ í•™ìŠµ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ\")\n",
    "print(f'lr = {lr}, epoch = {num_epochs}')\n",
    "print(f'ğŸŒŸ Best ëª¨ë¸ ì €ì¥ë¨ ({best_epoch} epochì—ì„œ AUC={best_auc:.4f}): {best_model_path}ë¡œ ì €ì¥ë¨')\n",
    "\n",
    "print_confusion_matrix(true_bin,pred_bin)     #confusion_matrix(ì´ì§„ ë¶„ë¥˜)\n",
    "print_confusion_matrix_method(true_method, pred_method)  #confusion_matrix(ë‹¤ì¤‘ ë¶„ë¥˜)\n",
    "plot_roc_curve(true_bin, output_bin_all, checkpoint_path, checkpoint_name) # ROC Curve (ì´ì§„ ë¶„ë¥˜)\n",
    "plot_tsne(feature_array, true_method, checkpoint_path, checkpoint_name,    # t-SNE (ë‹¤ì¤‘ ë¶„ë¥˜)\n",
    "          method_labels=['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face', 'others'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxgBUK9Mx0Gl"
   },
   "source": [
    "# FaceForencis++ test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzGGHmGuezSE"
   },
   "outputs": [],
   "source": [
    "# # ì½”ë© ì„œë²„\n",
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "checkpoint_name=\"checkpoint_v33\"\n",
    "\n",
    "test_input_file_path='/content/drive/MyDrive/Capstone/Dataset/ff++/test/*/*'\n",
    "# test_input_file_path2='/content/drive/MyDrive/Capstone/Dataset/DFDC/test/*/*'\n",
    "# test_input_file_path3='/content/drive/MyDrive/Capstone/Dataset/celeb-df/test/*/*'\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/ff++'\n",
    "base_path = '/content/drive/MyDrive/Capstone/Dataset'  # ìƒëŒ€ ì£¼ì†Œ ì°¾ê¸° ìœ„í•´ base_path ì œê±°\n",
    "frames=150\n",
    "\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"Dataset: FaceForencis++\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print()\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "#Model with feature visualization\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           #  model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "           #  self.model = model.extract_features\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()    # ì´ê±°ëŠ” ë„£ê³  ë¹¼ê³  ì‹¤í—˜í•´ë³´ë˜\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        # self.linear1 = nn.Linear(hidden_dim,num_classes) # hidden_dim ë³€ìˆ˜ë¡œ ë„£ì–´ì¤Œ\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # ë‘ ê°œì˜ ì¶œë ¥: ì´ì§„ ë¶„ë¥˜ì™€ method ë¶„ë¥˜\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        # return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = get_device()\n",
    "print(f\"âœ… Using device: {device}\")\n",
    "\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ì •ì˜\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "model.load_state_dict(torch.load(f'{checkpoint_path}/{checkpoint_name}.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Output confusion matrix   ì„±ëŠ¥ í‰ê°€\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix  #ë‚´ê°€ ì¶”ê°€í•¨\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Output confusion matrix / ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'ë¡œ ì •ìˆ˜ í‘œí˜„\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(test).png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # ì„±ëŠ¥ ì¶œë ¥\n",
    "    print(\"ğŸ“Š Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "def print_confusion_matrix_method(y_true_method, y_pred_method):\n",
    "\n",
    "    labels = ['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face','others']\n",
    "    label_indices = list(range(len(labels))) # [0, 1, 2, ..., 6]\n",
    "    cm = confusion_matrix(y_true_method, y_pred_method, labels=label_indices)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Blues')\n",
    "    plt.ylabel('Actual label', size=16)\n",
    "    plt.xlabel('Predicted label', size=16)\n",
    "    plt.xticks(np.arange(len(labels)) + 0.5, labels, rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(np.arange(len(labels)) + 0.5, labels, rotation=0, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(method)(test).png')\n",
    "\n",
    "    # ì •í™•ë„ ê³„ì‚°: ëª¨ë“  ì •ë‹µ ì˜ˆì¸¡ ìˆ˜ / ì „ì²´ ìƒ˜í”Œ ìˆ˜\n",
    "    correct_preds = np.trace(cm)\n",
    "    total_preds = np.sum(cm)\n",
    "    calculated_acc = correct_preds / total_preds\n",
    "    print(f\"\\nâœ… Calculated Accuracy: {calculated_acc * 100:.2f}%\")\n",
    "\n",
    "    # ì„±ëŠ¥ ì¶œë ¥\n",
    "    print(\"ğŸ“Š Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "    print(classification_report(y_true_method, y_pred_method, target_names=labels, labels=label_indices))\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    pred_score = output_bin.cpu().numpy()  # Real í™•ë¥ \n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve(test).png\")\n",
    "    print(f\"âœ… ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve(test).png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(features, labels, checkpoint_path, checkpoint_name, method_labels=None):\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, max(5, n_samples // 3))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_classes = np.unique(labels)\n",
    "    for cls in unique_classes:\n",
    "        idx = labels == cls\n",
    "        label_name = method_labels[cls] if method_labels and cls < len(method_labels) else str(cls)\n",
    "        plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=label_name, alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Method Class Features')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_tsne(test).png\")\n",
    "    print(f\"âœ… t-SNE plot saved to {checkpoint_path}/{checkpoint_name}_tsne(test).png\")\n",
    "\n",
    "def plot_tsne_binary(features, labels, checkpoint_path, checkpoint_name):\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, max(5, n_samples // 3))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cls in np.unique(labels):\n",
    "        idx = labels == cls\n",
    "        label_name = 'REAL' if cls == 1 else 'FAKE'\n",
    "        plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=label_name, alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Binary Classification Features')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_tsne_binary(test).png\")\n",
    "    print(f\"âœ… t-SNE (Binary) plot saved to {checkpoint_path}/{checkpoint_name}_tsne_binary(test).png\")\n",
    "\n",
    "#2. to load preprocessod video to memory / ì „ì²˜ë¦¬ëœ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°\n",
    "new_video_files =  glob.glob(f'{test_input_file_path}/*.mp4')\n",
    "\n",
    "random.shuffle(new_video_files)\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "method_pred_list = []  # ROC Curve ìš©\n",
    "video_bin_scores = []   # t-SNE ì‹œê°í™”ìš©\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "results = []\n",
    "label_list = []\n",
    "folder_path_list = []\n",
    "method_list = []\n",
    "\n",
    "\n",
    "video_feature_array = []\n",
    "with torch.no_grad():\n",
    "    for video_path in tqdm(new_video_files):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_preds = []\n",
    "        method_preds=[]\n",
    "        pooled_features_per_video = []\n",
    "        frame_scores = []\n",
    "\n",
    "        frame_idx = 0\n",
    "\n",
    "        relative_path = os.path.relpath(video_path,base_path).replace(\"\\\\\", \"/\")\n",
    "        folder_path_list.append(relative_path)\n",
    "\n",
    "        # label (real/fake)\n",
    "        if 'real' in relative_path.lower():\n",
    "            label = 'REAL'\n",
    "        elif 'fake' in relative_path.lower():\n",
    "            label = 'FAKE'\n",
    "        else:\n",
    "            label = 'unknown'\n",
    "        label_list.append(label)\n",
    "\n",
    "        # method (original/Deepfakes/FaceShifter/FaceSwap/NeuralTextures/Face2Face/unknown)\n",
    "        if 'original' in relative_path.lower():\n",
    "            method = 'original'\n",
    "        elif 'deepfakes' in relative_path.lower():\n",
    "            method = 'Deepfakes'\n",
    "        elif 'faceshifter' in relative_path.lower():\n",
    "            method = 'FaceShifter'\n",
    "        elif 'faceswap' in relative_path.lower():\n",
    "            method = 'FaceSwap'\n",
    "        elif 'neuraltextures' in relative_path.lower():\n",
    "            method = 'NeuralTextures'\n",
    "        elif 'face2face' in relative_path.lower():\n",
    "            method = 'Face2Face'\n",
    "        else:\n",
    "            method = 'others'\n",
    "        method_list.append(method)\n",
    "\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "        while success:\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 1 == 0:  # ë§¤ 5ë²ˆì§¸ í”„ë ˆì„ë§Œ ë½‘ì•„ì„œ ì˜ˆì¸¡ (ì†ë„ + ëŒ€í‘œì„±)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_tensor = transform(frame)\n",
    "                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (batch=1, seq_len=1, c=3, h, w)\n",
    "                input_tensor = input_tensor.to(device).float()\n",
    "\n",
    "                fmap, output_bin, output_method = model(input_tensor)\n",
    "                _, predicted_bin = torch.max(output_bin, 1)\n",
    "                _, predicted_method = torch.max(output_method, 1)\n",
    "\n",
    "                # ì¶”ê°€: threshold ê¸°ë°˜ unknown ë¶„ë¥˜ ì²˜ë¦¬\n",
    "                method_probs = torch.softmax(output_method.squeeze(0), dim=0)\n",
    "                method_confidence, method_class = torch.max(method_probs, dim=0)\n",
    "                threshold = 0.5  # â† ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ì¡°ì ˆ\n",
    "\n",
    "                if method_confidence < threshold:\n",
    "                    predicted_method = torch.tensor([6])  # unknown class\n",
    "                else:\n",
    "                    predicted_method = method_class.unsqueeze(0)  # ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "\n",
    "\n",
    "                score = torch.softmax(output_bin.squeeze(0), dim=0)[1].item()  # Real í™•ë¥ ë§Œ\n",
    "                frame_scores.append(score)\n",
    "\n",
    "                frame_preds.append(predicted_bin.item())\n",
    "                method_preds.append(predicted_method.item())\n",
    "                pooled = torch.mean(fmap.view(fmap.size(0), fmap.size(1), -1), dim=2)\n",
    "                pooled_features_per_video.append(pooled.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "            success, frame = cap.read()\n",
    "\n",
    "        # â¬‡ï¸ í”„ë ˆì„ í‰ê· ì„ ë¹„ë””ì˜¤ featureë¡œ ì €ì¥\n",
    "        if pooled_features_per_video:\n",
    "            avg_feature = np.mean(pooled_features_per_video, axis=0)\n",
    "            video_feature_array.append(avg_feature)\n",
    "\n",
    "        if frame_scores:\n",
    "            video_bin_scores.append(np.mean(frame_scores))\n",
    "\n",
    "        cap.release()\n",
    "        final_prediction = 'Unknown' if len(frame_preds) == 0 else ('REAL' if round(sum(frame_preds)/len(frame_preds)) == 1 else 'FAKE')\n",
    "        majority_method = max(set(method_preds), key=method_preds.count) if method_preds else 6\n",
    "        method_pred_list.append(majority_method)\n",
    "\n",
    "        results.append({\n",
    "            'Filename': os.path.basename(video_path),\n",
    "            'Filepath': video_path,\n",
    "            'label': label,\n",
    "            'Prediction': final_prediction,\n",
    "            'method': method,  # ì‹¤ì œ method\n",
    "            'Predicted_method': majority_method  # ì˜ˆì¸¡ëœ method\n",
    "        })\n",
    "\n",
    "# ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥\n",
    "output_excel_path = f'{checkpoint_path}/(test)_{checkpoint_name}_predictions.xlsx'\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"âœ… ëª¨ë“  ë¹„ë””ì˜¤ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—‘ì…€ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_excel_path}\")\n",
    "\n",
    "y_true = label_list\n",
    "y_pred = [r['Prediction'] for r in results]\n",
    "true_bin = [0 if l == 'FAKE' else 1 for l in y_true]\n",
    "pred_bin = [0 if p == 'FAKE' else 1 for p in y_pred]\n",
    "method_dict = {'original': 0, 'Deepfakes': 1, 'FaceShifter': 2, 'FaceSwap': 3, 'NeuralTextures': 4, 'Face2Face': 5, 'others': 6}\n",
    "true_method = [method_dict.get(m, 6) for m in method_list]\n",
    "pred_method = method_pred_list\n",
    "\n",
    "print(\"\\n================ Test Report ================\")\n",
    "print_confusion_matrix(true_bin, pred_bin)\n",
    "print_confusion_matrix_method(true_method, pred_method)\n",
    "\n",
    "# âœ… ROC Curve ë° t-SNE ì‹œê°í™”\n",
    "plot_roc_curve(torch.tensor(true_bin), torch.tensor(video_bin_scores), checkpoint_path, f\"{checkpoint_name}\")\n",
    "plot_tsne(np.array(video_feature_array), true_method, checkpoint_path, f\"{checkpoint_name}\",\n",
    "          method_labels=['original', 'Deepfakes', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'Face2Face', 'others'])\n",
    "plot_tsne_binary(np.array(video_feature_array), np.array(pred_bin), checkpoint_path, f\"{checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXcy769nAuj6"
   },
   "source": [
    "## CELEB-DF test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH18rfi5AuBx"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # ì½”ë© ì„œë²„import sys\n",
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "checkpoint_name=\"checkpoint_v33\"\n",
    "\n",
    "test_input_file_path='/content/drive/MyDrive/Capstone/Dataset/celeb-df/*'\n",
    "# test_input_file_path2='/content/drive/MyDrive/Capstone/Dataset/DFDC/test/*/*'\n",
    "# test_input_file_path3='/content/drive/MyDrive/Capstone/Dataset/celeb-df/test/*/*'\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/celeb-df'\n",
    "base_path = '/content/drive/MyDrive/Capstone/Dataset'  # ìƒëŒ€ ì£¼ì†Œ ì°¾ê¸° ìœ„í•´ base_path ì œê±°\n",
    "frames=150\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"Dataset: CELEB-DF\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print()\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "#Model with feature visualization\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           #  model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "           #  self.model = model.extract_features\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()    # ì´ê±°ëŠ” ë„£ê³  ë¹¼ê³  ì‹¤í—˜í•´ë³´ë˜\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        # self.linear1 = nn.Linear(hidden_dim,num_classes) # hidden_dim ë³€ìˆ˜ë¡œ ë„£ì–´ì¤Œ\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # ë‘ ê°œì˜ ì¶œë ¥: ì´ì§„ ë¶„ë¥˜ì™€ method ë¶„ë¥˜\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        # return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = get_device()\n",
    "print(f\"âœ… Using device: {device}\")\n",
    "\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ì •ì˜\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "model.load_state_dict(torch.load(f'{checkpoint_path}/{checkpoint_name}.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Output confusion matrix   ì„±ëŠ¥ í‰ê°€\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix  #ë‚´ê°€ ì¶”ê°€í•¨\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Output confusion matrix / ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'ë¡œ ì •ìˆ˜ í‘œí˜„\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(test_celebdf).png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # ì„±ëŠ¥ ì¶œë ¥\n",
    "    print(\"ğŸ“Š Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    pred_score = output_bin.cpu().numpy()  # Real í™•ë¥ \n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve(test_celebdf).png\")\n",
    "    print(f\"âœ… ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve(test_celebdf).png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#2. to load preprocessod video to memory / ì „ì²˜ë¦¬ëœ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°\n",
    "new_video_files =  glob.glob(f'{test_input_file_path}/*.mp4')\n",
    "\n",
    "random.shuffle(new_video_files)\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "method_pred_list = []  # ROC Curve ìš©\n",
    "video_bin_scores = []   # t-SNE ì‹œê°í™”ìš©\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "results = []\n",
    "label_list = []\n",
    "folder_path_list = []\n",
    "method_list = []\n",
    "\n",
    "\n",
    "video_feature_array = []\n",
    "with torch.no_grad():\n",
    "    for video_path in tqdm(new_video_files):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_preds = []\n",
    "        method_preds=[]\n",
    "        pooled_features_per_video = []\n",
    "        frame_scores = []\n",
    "\n",
    "        frame_idx = 0\n",
    "\n",
    "        relative_path = os.path.relpath(video_path,base_path).replace(\"\\\\\", \"/\")\n",
    "        folder_path_list.append(relative_path)\n",
    "\n",
    "        # label (real/fake)\n",
    "        if 'real' in relative_path.lower():\n",
    "            label = 'REAL'\n",
    "        elif 'fake' in relative_path.lower():\n",
    "            label = 'FAKE'\n",
    "        else:\n",
    "            label = 'unknown'\n",
    "        label_list.append(label)\n",
    "\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "        while success:\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 1 == 0:  # ë§¤ 5ë²ˆì§¸ í”„ë ˆì„ë§Œ ë½‘ì•„ì„œ ì˜ˆì¸¡ (ì†ë„ + ëŒ€í‘œì„±)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_tensor = transform(frame)\n",
    "                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (batch=1, seq_len=1, c=3, h, w)\n",
    "                input_tensor = input_tensor.to(device).float()\n",
    "\n",
    "                fmap, output_bin, output_method = model(input_tensor)\n",
    "                _, predicted_bin = torch.max(output_bin, 1)\n",
    "                _, predicted_method = torch.max(output_method, 1)\n",
    "\n",
    "                # ì¶”ê°€: threshold ê¸°ë°˜ unknown ë¶„ë¥˜ ì²˜ë¦¬\n",
    "                method_probs = torch.softmax(output_method.squeeze(0), dim=0)\n",
    "                method_confidence, method_class = torch.max(method_probs, dim=0)\n",
    "                threshold = 0.5  # â† ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ì¡°ì ˆ\n",
    "\n",
    "                if method_confidence < threshold:\n",
    "                    predicted_method = torch.tensor([6])  # unknown class\n",
    "                else:\n",
    "                    predicted_method = method_class.unsqueeze(0)  # ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "\n",
    "\n",
    "                score = torch.softmax(output_bin.squeeze(0), dim=0)[1].item()  # Real í™•ë¥ ë§Œ\n",
    "                frame_scores.append(score)\n",
    "\n",
    "                frame_preds.append(predicted_bin.item())\n",
    "                method_preds.append(predicted_method.item())\n",
    "\n",
    "                pooled = torch.mean(fmap.view(fmap.size(0), fmap.size(1), -1), dim=2)\n",
    "                pooled_features_per_video.append(pooled.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "            success, frame = cap.read()\n",
    "\n",
    "        # â¬‡ï¸ í”„ë ˆì„ í‰ê· ì„ ë¹„ë””ì˜¤ featureë¡œ ì €ì¥\n",
    "        if pooled_features_per_video:\n",
    "            avg_feature = np.mean(pooled_features_per_video, axis=0)\n",
    "            video_feature_array.append(avg_feature)\n",
    "\n",
    "        if frame_scores:\n",
    "            video_bin_scores.append(np.mean(frame_scores))\n",
    "\n",
    "        cap.release()\n",
    "        final_prediction = 'Unknown' if len(frame_preds) == 0 else ('REAL' if round(sum(frame_preds)/len(frame_preds)) == 1 else 'FAKE')\n",
    "        majority_method = max(set(method_preds), key=method_preds.count) if method_preds else 6\n",
    "        method_pred_list.append(majority_method)\n",
    "\n",
    "        results.append({\n",
    "            'Filename': os.path.basename(video_path),\n",
    "            'Filepath': video_path,\n",
    "            'label': label,\n",
    "            'Prediction': final_prediction,\n",
    "            # 'method': method,  # ì‹¤ì œ method\n",
    "            'Predicted_method': majority_method  # ì˜ˆì¸¡ëœ method\n",
    "        })\n",
    "\n",
    "# ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥\n",
    "output_excel_path = f'{checkpoint_path}/(test)_{checkpoint_name}_predictions_celebdf.xlsx'\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"âœ… ëª¨ë“  ë¹„ë””ì˜¤ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—‘ì…€ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_excel_path}\")\n",
    "\n",
    "y_true = label_list\n",
    "y_pred = [r['Prediction'] for r in results]\n",
    "true_bin = [0 if l == 'FAKE' else 1 for l in y_true]\n",
    "pred_bin = [0 if p == 'FAKE' else 1 for p in y_pred]\n",
    "pred_method = method_pred_list\n",
    "\n",
    "print(\"\\n================ Test Report ================\")\n",
    "print_confusion_matrix(true_bin, pred_bin)\n",
    "\n",
    "# âœ… ROC Curve\n",
    "plot_roc_curve(torch.tensor(true_bin), torch.tensor(video_bin_scores), checkpoint_path, f\"{checkpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_wqHU33pnQH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def compute_eer(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "    return fpr[eer_idx], thresholds[eer_idx]\n",
    "\n",
    "def compute_pauc(y_true, y_scores, fpr_limit=0.1):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    mask = fpr <= fpr_limit\n",
    "    return auc(fpr[mask], tpr[mask]) / fpr_limit\n",
    "\n",
    "\n",
    "# FAKEë¥¼ positive class (1)ë¡œ ë³´ê¸° ìœ„í•´ ì ìˆ˜ ë’¤ì§‘ê¸°\n",
    "video_fake_scores = [1 - s for s in video_bin_scores]\n",
    "true_bin = [1 if l == 'FAKE' else 0 for l in y_true]\n",
    "\n",
    "# AUC / EER / pAUC ê³„ì‚°\n",
    "auc_val = roc_auc_score(true_bin, video_fake_scores)\n",
    "eer, eer_threshold = compute_eer(true_bin, video_fake_scores)\n",
    "pauc = compute_pauc(true_bin, video_fake_scores)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"AUC (FAKE=1 ê¸°ì¤€): {auc_val:.4f}\")\n",
    "print(f\"EER (FAKE=1 ê¸°ì¤€): {eer:.4f} at threshold {eer_threshold:.4f}\")\n",
    "print(f\"pAUC@0.1 (FAKE=1 ê¸°ì¤€): {pauc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUFAga0_Eku-"
   },
   "source": [
    "### DeeperForencis test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpeql_xHEgk6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # ì½”ë© ì„œë²„import sys\n",
    "import sys\n",
    "selected_model = \"resnext50_32x4d\"\n",
    "checkpoint_name=\"checkpoint_v33\"\n",
    "\n",
    "test_input_file_path='/content/drive/MyDrive/Capstone/Dataset/DeeperForensics/*'\n",
    "# test_input_file_path2='/content/drive/MyDrive/Capstone/Dataset/DFDC/test/*/*'\n",
    "# test_input_file_path3='/content/drive/MyDrive/Capstone/Dataset/celeb-df/test/*/*'\n",
    "checkpoint_path=f'/content/drive/MyDrive/Capstone/checkpoints/{checkpoint_name}'\n",
    "meta_data_path='/content/drive/MyDrive/Capstone/Dataset/DeeperForensics'\n",
    "base_path = '/content/drive/MyDrive/Capstone/Dataset'  # ìƒëŒ€ ì£¼ì†Œ ì°¾ê¸° ìœ„í•´ base_path ì œê±°\n",
    "frames=150\n",
    "\n",
    "print(\"Check parameter\")\n",
    "print(f\"Dataset: DeeperForensics\")\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "print()\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "#Model with feature visualization\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_binary_classes=2, num_method_classes=7,model_name=\"resnext50_32x4d\", lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name==\"resnext50_32x4d\":\n",
    "          model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "          self.latent_dim = 2048\n",
    "        elif self.model_name==\"xception\":\n",
    "          self.latent_dim = 2048 # xception\n",
    "          model = timm.create_model('xception', pretrained=True, features_only=False)\n",
    "          self.model = nn.Sequential(*list(model.children())[:-2])  # or model.forward_features\n",
    "        elif self.model_name==\"EfficientNet-b0\":\n",
    "           self.latent_dim = 1280 # efficient\n",
    "           #  model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "           #  self.model = model.extract_features\n",
    "           weights = EfficientNet_B0_Weights.DEFAULT\n",
    "           model = efficientnet_b0(weights=weights)\n",
    "           self.model = nn.Sequential(*list(model.features))\n",
    "        print(\"latet_dim: \",self.latent_dim)\n",
    "        self.lstm = nn.LSTM(self.latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()    # ì´ê±°ëŠ” ë„£ê³  ë¹¼ê³  ì‹¤í—˜í•´ë³´ë˜\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        # self.linear1 = nn.Linear(hidden_dim,num_classes) # hidden_dim ë³€ìˆ˜ë¡œ ë„£ì–´ì¤Œ\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        # ë‘ ê°œì˜ ì¶œë ¥: ì´ì§„ ë¶„ë¥˜ì™€ method ë¶„ë¥˜\n",
    "        self.binary_classifier = nn.Linear(hidden_dim, num_binary_classes)\n",
    "        self.method_classifier = nn.Linear(hidden_dim, num_method_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,self.latent_dim) # resnext50_32x4d, xception : 2048, efficientnet-b0 : 1280\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        # return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n",
    "        pooled = torch.mean(x_lstm, dim=1)\n",
    "        return fmap, self.binary_classifier(self.dp(pooled)), self.method_classifier(self.dp(pooled))\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS is available. Using MPS.\")\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA and MPS not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = get_device()\n",
    "print(f\"âœ… Using device: {device}\")\n",
    "\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ì •ì˜\n",
    "model = Model(num_binary_classes=2, num_method_classes=7, model_name=selected_model).to(device)\n",
    "model.load_state_dict(torch.load(f'{checkpoint_path}/{checkpoint_name}.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Output confusion matrix   ì„±ëŠ¥ í‰ê°€\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix  #ë‚´ê°€ ì¶”ê°€í•¨\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Output confusion matrix / ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.clf()  # Clear the previous figure\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d', annot_kws={\"size\": 16}) # font size ,fmt='d'ë¡œ ì •ìˆ˜ í‘œí˜„\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{checkpoint_path}/{checkpoint_name}_plot(test_deeperforencis).png')\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "\n",
    "    y_true = (['Fake'] * sum(cm[0]) + ['Real'] * sum(cm[1]))\n",
    "    y_pred = (['Fake'] * cm[0][0] + ['Real'] * cm[0][1] +\n",
    "            ['Fake'] * cm[1][0] + ['Real'] * cm[1][1])\n",
    "\n",
    "    # ì„±ëŠ¥ ì¶œë ¥\n",
    "    print(\"ğŸ“Š Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "def plot_roc_curve(true_bin, output_bin, checkpoint_path, checkpoint_name):\n",
    "    pred_score = output_bin.cpu().numpy()  # Real í™•ë¥ \n",
    "    fpr, tpr, _ = roc_curve(true_bin, pred_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Binary Classification)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{checkpoint_path}/{checkpoint_name}_roc_curve(test_deeperforenciss).png\")\n",
    "    print(f\"âœ… ROC Curve saved to {checkpoint_path}/{checkpoint_name}_roc_curve(test_deeperforencis).png\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#2. to load preprocessod video to memory / ì „ì²˜ë¦¬ëœ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°\n",
    "new_video_files =  glob.glob(f'{test_input_file_path}/*.mp4')\n",
    "\n",
    "random.shuffle(new_video_files)\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "method_pred_list = []  # ROC Curve ìš©\n",
    "video_bin_scores = []   # t-SNE ì‹œê°í™”ìš©\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "results = []\n",
    "label_list = []\n",
    "folder_path_list = []\n",
    "method_list = []\n",
    "\n",
    "\n",
    "video_feature_array = []\n",
    "with torch.no_grad():\n",
    "    for video_path in tqdm(new_video_files):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_preds = []\n",
    "        method_preds=[]\n",
    "        pooled_features_per_video = []\n",
    "        frame_scores = []\n",
    "\n",
    "        frame_idx = 0\n",
    "\n",
    "        relative_path = os.path.relpath(video_path,base_path).replace(\"\\\\\", \"/\")\n",
    "        folder_path_list.append(relative_path)\n",
    "\n",
    "        # label (real/fake)\n",
    "        if 'real' in relative_path.lower():\n",
    "            label = 'REAL'\n",
    "        elif 'fake' in relative_path.lower():\n",
    "            label = 'FAKE'\n",
    "        else:\n",
    "            label = 'unknown'\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "        while success:\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 1 == 0:  # ë§¤ 5ë²ˆì§¸ í”„ë ˆì„ë§Œ ë½‘ì•„ì„œ ì˜ˆì¸¡ (ì†ë„ + ëŒ€í‘œì„±)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_tensor = transform(frame)\n",
    "                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (batch=1, seq_len=1, c=3, h, w)\n",
    "                input_tensor = input_tensor.to(device).float()\n",
    "\n",
    "                fmap, output_bin, output_method = model(input_tensor)\n",
    "                _, predicted_bin = torch.max(output_bin, 1)\n",
    "                _, predicted_method = torch.max(output_method, 1)\n",
    "\n",
    "                # ì¶”ê°€: threshold ê¸°ë°˜ unknown ë¶„ë¥˜ ì²˜ë¦¬\n",
    "                method_probs = torch.softmax(output_method.squeeze(0), dim=0)\n",
    "                method_confidence, method_class = torch.max(method_probs, dim=0)\n",
    "                threshold = 0.5  # â† ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ì¡°ì ˆ\n",
    "\n",
    "                if method_confidence < threshold:\n",
    "                    predicted_method = torch.tensor([6])  # unknown class\n",
    "                else:\n",
    "                    predicted_method = method_class.unsqueeze(0)  # ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "\n",
    "                score = torch.softmax(output_bin.squeeze(0), dim=0)[1].item()  # Real í™•ë¥ ë§Œ\n",
    "                frame_scores.append(score)\n",
    "\n",
    "                frame_preds.append(predicted_bin.item())\n",
    "                method_preds.append(predicted_method.item())\n",
    "\n",
    "                pooled = torch.mean(fmap.view(fmap.size(0), fmap.size(1), -1), dim=2)\n",
    "                pooled_features_per_video.append(pooled.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "            success, frame = cap.read()\n",
    "\n",
    "        # â¬‡ï¸ í”„ë ˆì„ í‰ê· ì„ ë¹„ë””ì˜¤ featureë¡œ ì €ì¥\n",
    "        if pooled_features_per_video:\n",
    "            avg_feature = np.mean(pooled_features_per_video, axis=0)\n",
    "            video_feature_array.append(avg_feature)\n",
    "\n",
    "        if frame_scores:\n",
    "            video_bin_scores.append(np.mean(frame_scores))\n",
    "\n",
    "        cap.release()\n",
    "        final_prediction = 'Unknown' if len(frame_preds) == 0 else ('REAL' if round(sum(frame_preds)/len(frame_preds)) == 1 else 'FAKE')\n",
    "        majority_method = max(set(method_preds), key=method_preds.count) if method_preds else 6\n",
    "        method_pred_list.append(majority_method)\n",
    "\n",
    "        results.append({\n",
    "            'Filename': os.path.basename(video_path),\n",
    "            'Filepath': video_path,\n",
    "            'label': label,\n",
    "            'Prediction': final_prediction,\n",
    "            # 'method': method,  # ì‹¤ì œ method\n",
    "            'Predicted_method': majority_method  # ì˜ˆì¸¡ëœ method\n",
    "        })\n",
    "\n",
    "# ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥\n",
    "output_excel_path = f'{checkpoint_path}/(test)_{checkpoint_name}_predictions_deeperforencis.xlsx'\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"âœ… ëª¨ë“  ë¹„ë””ì˜¤ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—‘ì…€ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_excel_path}\")\n",
    "\n",
    "y_true = label_list\n",
    "y_pred = [r['Prediction'] for r in results]\n",
    "true_bin = [0 if l == 'FAKE' else 1 for l in y_true]\n",
    "pred_bin = [0 if p == 'FAKE' else 1 for p in y_pred]\n",
    "pred_method = method_pred_list\n",
    "\n",
    "print(\"\\n================ Test Report ================\")\n",
    "print_confusion_matrix(true_bin, pred_bin)\n",
    "# print_confusion_matrix_method(true_method, pred_method)\n",
    "\n",
    "# âœ… ROC Curve ë° t-SNE ì‹œê°í™”\n",
    "plot_roc_curve(torch.tensor(true_bin), torch.tensor(video_bin_scores), checkpoint_path, f\"{checkpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_KI7nWsEp26"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def compute_eer(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "    return fpr[eer_idx], thresholds[eer_idx]\n",
    "\n",
    "def compute_pauc(y_true, y_scores, fpr_limit=0.1):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    mask = fpr <= fpr_limit\n",
    "    return auc(fpr[mask], tpr[mask]) / fpr_limit\n",
    "\n",
    "\n",
    "# FAKEë¥¼ positive class (1)ë¡œ ë³´ê¸° ìœ„í•´ ì ìˆ˜ ë’¤ì§‘ê¸°\n",
    "video_fake_scores = [1 - s for s in video_bin_scores]\n",
    "true_bin = [1 if l == 'FAKE' else 0 for l in y_true]\n",
    "\n",
    "# AUC / EER / pAUC ê³„ì‚°\n",
    "auc_val = roc_auc_score(true_bin, video_fake_scores)\n",
    "eer, eer_threshold = compute_eer(true_bin, video_fake_scores)\n",
    "pauc = compute_pauc(true_bin, video_fake_scores)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"AUC (FAKE=1 ê¸°ì¤€): {auc_val:.4f}\")\n",
    "print(f\"EER (FAKE=1 ê¸°ì¤€): {eer:.4f} at threshold {eer_threshold:.4f}\")\n",
    "print(f\"pAUC@0.1 (FAKE=1 ê¸°ì¤€): {pauc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzH84v0rz/jVmTZkJUBesI",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
