{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPixZx4M8G1TVWwqXDYtfXR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install facenet-pytorch"],"metadata":{"id":"p0xqiogEb_I1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from facenet_pytorch import MTCNN\n","import cv2\n","import os\n","import glob\n","import tqdm\n","import torch\n","import json\n","import glob\n","import numpy as np\n","import copy\n","import pandas as pd\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import matplotlib.pyplot as plt\n","import tqdm"],"metadata":{"id":"_o8If1cJnnh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive to access files in Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eUN0HMJrYh3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ Set the device to MPS(for Mac) if available, otherwise fallback to CUDA or CPU\n","device = torch.device(\"mps\") if torch.backends.mps.is_available() else (\n","  torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"CFsVUJY0eCDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the average number of frames per video\n","def average_frame_count(input_file_path):\n","  input_path = f'{input_file_path}/*.mp4'\n","  video_files = glob.glob(input_path)\n","  frame_count = []\n","  video_list = []\n","  short_frame=[]\n","  short_frame_count=[]\n","  for video_file in video_files:\n","    cap = cv2.VideoCapture(video_file)\n","    if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n","      short_frame.append(video_file)\n","      short_frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n","      #video_files.remove(video_file) # 삭제 대신 리스트에 추가하여 목록 관리\n","      continue\n","    video_list.append(video_file) # 프레임 150 이상인 영상들\n","    frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n","    cap.release()\n","\n","  print(\"Total number of videos: \" , len(frame_count))\n","  print('Average frame per video:',np.mean(frame_count))\n","  print('Short frame video:',len(short_frame))\n","\n","  return video_list\n","\n","\n","\n","# Extract frame from video - 비디오 파일에서 프레임 추출\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image\n","\n","# Create face videos by detecting faces in each frame\n","def create_face_videos(path_list, out_dir):\n","    already_present_count = glob.glob(out_dir + '/*.mp4')\n","    print(\"No of videos already present:\", len(already_present_count))\n","\n","    for path in tqdm.tqdm(path_list):\n","        out_path = os.path.join(out_dir, os.path.basename(path))\n","\n","        # Skip if the video already exists\n","        if os.path.exists(out_path):\n","            print(\"File already exists:\", out_path)\n","            continue\n","\n","        frames = []\n","        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'MJPG'), 30, (224,224))\n","\n","        for idx, frame in enumerate(frame_extract(path)):\n","            # if idx > 150:\n","            #     break\n","\n","            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","            # Face detection using MTCNN\n","            box, _ = mtcnn.detect(rgb_frame)\n","\n","            if box is not None:\n","                x1, y1, x2, y2 = map(int, box[0])  # Use the first detected face\n","                x1 = max(0, x1)\n","                y1 = max(0, y1)\n","                x2 = min(frame.shape[1], x2)\n","                y2 = min(frame.shape[0], y2)\n","\n","                face = frame[y1:y2, x1:x2]\n","                if face.size != 0:\n","                    resized_face = cv2.resize(face, (224,224))\n","                    out.write(resized_face)\n","\n","        out.release()"],"metadata":{"id":"XBukgIZsQrz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","input_file_path='/content/drive/MyDrive/Capstone/Dataset/FaceForensics++_C23'\n","output_file_path='/content/drive/MyDrive/Capstone/Dataset/ff++'\n","data_details=\"NeuralTextures\"\n","\n","input_path = f\"{input_file_path}/{data_details}\"\n","output_path = f\"{output_file_path}/{data_details}\"\n","\n","# Initialize the MTCNN face detector\n","mtcnn = MTCNN(keep_all=False, device=device)\n","\n","video_files = average_frame_count(input_path)\n","create_face_videos(video_files, output_path)"],"metadata":{"id":"15rE6fUHoHKk"},"execution_count":null,"outputs":[]}]}